{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Метрики регрессии. Недостатки аналитического решения**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Итак, ранее мы с вами пришли к тому, что нам необходимо научиться оценивать качество модели с помощью какого-то показателя (или нескольких показателей). Такой показатель в машинном обучении называется **метрикой**. И для каждого класса задач машинного обучения существуют свои метрики.\n",
    "\n",
    "**Метрика** — это численное выражение качества моделирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **МЕТРИКИ РЕГРЕССИИ**\n",
    "\n",
    "Будем рассматривать метрики для задачи регрессии на следующем примере. Возьмём первые пять наблюдений из нашей таблицы и предсказанные для них моделью lr_full ответы:\n",
    "\n",
    "![](data\\f22.png)\n",
    "\n",
    "На этих значениях мы будем рассматривать следующие метрики:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. MAE (Mean Absolute Error) — Средняя абсолютная ошибка**\n",
    "\n",
    "Это самый простой и уже знакомый вам показатель. Чтобы посчитать данную метрику, нужно найти все остатки (разницы между предсказанным значением и реальным), взять от каждого из них модуль, сложить их и поделить на количество. Иными словами, нам нужно найти среднее арифметическое модуля отклонения предсказанного значения от реального.\n",
    "\n",
    "![](data\\f23.png)\n",
    "\n",
    "Данная метрика интерпретируется очень легко: **это число показывает, насколько в среднем наша модель ошибается. Чем меньше значение метрики, тем лучше.**\n",
    "\n",
    "![](data\\f24.png)\n",
    "\n",
    "То есть для нашего примера из пяти наблюдений в среднем модель ошибается на 4.482 тысячи долларов.\n",
    "\n",
    "Много ли это? Хороший вопрос, на который без эксперта-оценщика недвижимости будет сложно дать ответ. Однако можно попробовать посчитать ошибку в процентах, ведь в процентах всё воспринимается легче, и для этого нам пригодится следующая метрика — MAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. MAPE (Mean Absolute Percent Error) — Средняя абсолютная ошибка в процентах**\n",
    "\n",
    "Для её вычисления мы делим модуль разницы между предсказанием алгоритма и истинным значением на истинное значение. Затем складываем все результаты (для каждого объекта), делим на количество и умножаем на 100 %.\n",
    "\n",
    "![](data\\f25.png)\n",
    "\n",
    "Эта метрика показывает, **на сколько процентов в среднем наше предсказание отклоняется от реального значения**. Эта метрика отлично показывает себя в задачах, когда неизвестно, какое значение целевого показателя считать приемлемым.\n",
    "\n",
    "Например, средняя ошибка — 2 тысячи долларов. Это много или мало? Смотря для чего... А вот средняя ошибка, равная 80 % — это много или мало? Определённо много.\n",
    "\n",
    "![](data\\f26.png)\n",
    "\n",
    "Таким образом, на первых пяти наблюдениях модель в среднем ошибается на 15.781 %. Это довольно неплохой результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. MSE — Средняя квадратическая ошибка**\n",
    "\n",
    "Данный показатель мы используем в линейной регрессии в качестве функции потерь, но ничто не мешает нам также использовать его и в качестве метрики.\n",
    "\n",
    "Логика вычисления данной ошибки очень похожа на предыдущую. Разница лишь в том, что **вместо модуля разности между предсказанным и реальным значениями мы берём квадрат этого модуля**:\n",
    "\n",
    "![](data\\f27.png)\n",
    "\n",
    "***Данная метрика хуже поддаётся интерпретации, чем предыдущая, так как измеряется не в единицах, а в квадратах единиц. Она чаще используется для внутреннего обсуждения между дата-сайентистами, заказчику такая метрика может быть непонятна.***\n",
    "\n",
    "![](data\\f28.png)\n",
    "\n",
    "Таким образом, для нашего примера квадрат отклонения составляет 22.116 тысяч долларов в квадрате.\n",
    "\n",
    "Согласитесь, не очень понятно, о чём идет речь. Однако данная метрика является популярной, так как позволяет **«штрафовать»** модель за очень большие ошибки.\n",
    "\n",
    "Что значит «штрафовать»? \n",
    "\n",
    "Например, расхождение в 200 единиц в метрике MSE воспринимается как , а в метрике MAE это расхождение воспринимается как 200. Поэтому, если у нас есть две модели, но одна из них допускает большие ошибки, эти ошибки становятся ещё больше при расчёте метрики MSE, и нам легче сравнить модели между собой.\n",
    "\n",
    "***Но в то же время это и проклятие MSE. Если в данных присутствуют выбросы, метрика может быть необъективной. Если модель будет утверждать, что цена здания — 30 тысяч долларов, а в наборе данных ему соответствует цена в 3 миллиона долларов, то при возведении такой ошибки в квадрат получится 9 миллионов, что может сбить с толку исследователя. Необходимо скептически относиться к данной метрике, если вы не проводили исследование данных на предмет наличия выбросов.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. RMSE (Root Mean Squared Error) — Корень из средней квадратической ошибки**\n",
    "\n",
    "Для получения RMSE надо просто **извлечь квадратный корень из MSE**:\n",
    "\n",
    "![](data\\f29.png)\n",
    "\n",
    "Корень извлекается для того, чтобы привести размерности ответов и ошибок в соответствие и сделать метрику более понятной.\n",
    "\n",
    "![](data\\f30.png)\n",
    "\n",
    "Преимущества и недостатки этой метрики такие же, как и у MSE, к преимуществам добавляется только понятная размерность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. R^2 — Коэффициент детерминации**\n",
    "\n",
    "Все рассматриваемые ранее метрики имели масштаб от 0 до +∞. Чем это плохо?\n",
    "\n",
    "А что если нам скажут, что MSE для модели составляет 32? Должны ли мы улучшить модель, или она достаточно хороша? А что если MSE = 0.4?\n",
    "\n",
    "На самом деле, трудно понять, хороша модель или нет, не сравнив её показатели с теми же показателями других моделей.\n",
    "\n",
    "Коэффициент детерминации, или R^2, является ещё одним показателем, который мы можем использовать для оценки модели. Он тесно связан с MSE, но его преимущество в том, что **R^2 всегда находится в промежутке между -∞ и 1**.\n",
    "\n",
    "![](data\\f31.png)\n",
    "\n",
    "где\n",
    "\n",
    "![](data\\f32.png)\n",
    "\n",
    "где ***y*** с палкой — среднее по вектору правильных ответов.\n",
    "\n",
    "То есть R^2 показывает, насколько наша модель лучше, чем если бы все предсказания были средним по правильным ответам.\n",
    "\n",
    "Посмотрим, как считается R^2. Сначала рассчитаем среднее по правильным ответам:\n",
    "\n",
    "![](data\\f33.png)\n",
    "\n",
    "Теперь рассчитаем MSEmean:\n",
    "\n",
    "![](data\\f34.png)\n",
    "\n",
    "И, наконец, сам R^2:\n",
    "\n",
    "![](data\\f35.png)\n",
    "\n",
    "Есть ещё одна интерпретация данной метрики. **Статистически показатель R^2 описывает, какую долю информации о зависимости (дисперсии) смогла уловить модель.**\n",
    "\n",
    "***Удовлетворительным R^2 считается показатель выше 0.5: чем ближе к 1, тем лучше. Отрицательные значения R^2 говорят о том, что построенная модель настолько плоха, что лучше было бы присвоить всем ответам среднее значение.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ТАБЛИЦА-ОБОБЩЕНИЕ**\n",
    "\n",
    "Давайте обобщим всё вышесказанное в виде таблицы:\n",
    "\n",
    "![](data\\table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **РАСЧЁТ МЕТРИК НА PYTHON**\n",
    "\n",
    "Настало время проверить качество построенных нами ранее моделей линейной регрессии: **lr_lstat** и **lr_full**.\n",
    "\n",
    "Весь набор функций для вычисления метрик в sklearn находится в модуле **metrics**. Давайте его импортируем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\local_admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# всё остальное\n",
    "from sklearn import linear_model\n",
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') #установка стиля matplotlib\n",
    "\n",
    "from sklearn.datasets import load_boston \n",
    "boston = load_boston()\n",
    "\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "#добавляем в таблицу столбец с целевой переменной\n",
    "boston_data['MEDV'] = boston.target\n",
    "X = boston_data[['LSTAT']] #матрица наблюдений\n",
    "y = boston_data['MEDV'] #вектор правильных ответов\n",
    "\n",
    "#Создаём объект класса LinearRegression\n",
    "lr_lstat = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_lstat.fit(X, y)\n",
    "\n",
    "#Составляем список факторов (исключили целевой столбец)\n",
    "features = boston_data.drop('MEDV', axis=1).columns\n",
    "#Составляем матрицу наблюдений X и вектор ответов y\n",
    "X = boston_data[features]\n",
    "y = boston_data['MEDV']\n",
    "#Создаём объект класса LinearRegression\n",
    "lr_full = linear_model.LinearRegression()\n",
    "#Обучаем модель — ищем параметры по МНК\n",
    "lr_full.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции, которые нам понадобятся:\n",
    "\n",
    "* **mean_absolute_error()** — расчёт MAE;\n",
    "* **mean_square_error()** — расчёт MSE;\n",
    "* **mean_absolute_percentage_error()** — расчёт MAPE;\n",
    "* **r2_score()** — расчёт коэффициента детерминации R^2.\n",
    "\n",
    "В каждую из функций достаточно передать правильные ответы и предсказания, и функция вернёт рассчитанную метрику.\n",
    "\n",
    "***Примечание. Для расчёта метрики RMSE нет специальной функции, однако мы знаем, что для её расчёта достаточно извлечь квадратный корень из MSE.***  \n",
    "***Из-за особенностей реализации функция mean_absolute_percentage_error() возвращает результат не в процентах, а в долях. Чтобы отобразить результат в процентах, необходимо умножить его на 100.***\n",
    "\n",
    "Давайте вычислим метрики и выведем их на экран, округлив до третьего знака после запятой. Начнём с модели lr_lstat: сделаем предсказание на основании признака LSTAT и передадим истинные и предсказанные медианные цены в функции для расчёта метрик:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 4.505 thou. $\n",
      "RMSE score: 6.203 thou. $\n",
      "MAPE score: 21.352 %\n",
      "R2 score: 0.544\n"
     ]
    }
   ],
   "source": [
    "#Делаем предсказание по признаку LSTAT\n",
    "y_predict_lstat = lr_lstat.predict(boston_data[['LSTAT']])\n",
    "#Рассчитываем MAE\n",
    "print('MAE score: {:.3f} thou. $'.format(metrics.mean_absolute_error(y, y_predict_lstat)))\n",
    "#Рассчитываем RMSE\n",
    "print('RMSE score: {:.3f} thou. $'.format(np.sqrt(metrics.mean_squared_error(y, y_predict_lstat))))\n",
    "#Рассчитываем MAPE\n",
    "print('MAPE score: {:.3f} %'.format(metrics.mean_absolute_percentage_error(y, y_predict_lstat) * 100))\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict_lstat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 3.271 thou. $\n",
      "RMSE score: 4.679 thou. $\n",
      "MAPE score: 16.417 %\n",
      "R2 score: 0.741\n"
     ]
    }
   ],
   "source": [
    "# Проделываем ту же самую операцию для второй модели линейной регрессии, lr_full:\n",
    "\n",
    "#Делаем предсказание по всем признакам\n",
    "y_predict_full = lr_full.predict(boston_data[features])\n",
    "#Рассчитываем MAE\n",
    "print('MAE score: {:.3f} thou. $'.format(metrics.mean_absolute_error(y, y_predict_full)))\n",
    "#Рассчитываем RMSE\n",
    "print('RMSE score: {:.3f} thou. $'.format(np.sqrt(metrics.mean_squared_error(y, y_predict_full))))\n",
    "#Рассчитываем MAPE\n",
    "print('MAPE score: {:.3f} %'.format(metrics.mean_absolute_percentage_error(y, y_predict_full) * 100))\n",
    "#Рассчитываем коэффициент детерминации\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y, y_predict_full)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним полученные результаты:\n",
    "\n",
    "* MAE: в среднем первая модель ошибается на  4.505 тыс. долларов, а вторая — на 3.271 тыс. долларов.\n",
    "* RMSE: среднеквадратичное отклонение первой модели от истинных ответов составляет 6.203 тыс. долларов, а второй — 4.679.\n",
    "* MAPE: первая модель ошибается на 21.352 %, а вторая — на 16.417 %.\n",
    "* R^2: доля объясняемой информации (дисперсии), которую улавливает первая модель, — 0.544, а вторая — 0.741.\n",
    "* \n",
    "Очевидно, что по всем метрикам *вторая модель, построенная на основе всех признаков в данных, превосходит первую*.\n",
    "\n",
    "✍ Следует отметить, что для задач регрессии существует множество метрик, и мы рассмотрели только наиболее распространённые из них. Весь список метрик и их расчёт в sklearn вы можете найти [**здесь**](https://scikit-learn.ru/3-3-metrics-and-scoring-quantifying-the-quality-of-predictions/#regression-metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score: 5.750 thou. $\n"
     ]
    }
   ],
   "source": [
    "# У вас есть истинные ответы y_true = [1.23, 2.35, 2.75] и предсказания модели y_pred = [1.01, 12.3, 2.74].\n",
    "# Посчитайте метрику RMSE, ответ округлите до двух знаков после точки-разделителя.\n",
    "y_true = [1.23, 2.35, 2.75]\n",
    "y_pred = [1.01, 12.3, 2.74]\n",
    "print('RMSE score: {:.3f} thou. $'.format(np.sqrt(metrics.mean_squared_error(y_true, y_pred)).round(2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.710\n"
     ]
    }
   ],
   "source": [
    "# Чему равен коэффициент детерминации (R^2) на следующих данных?\n",
    "y_true = [22.4, 20.6, 23.9, 22.0, 11.9]\n",
    "y_pred = [20.5, 20.2, 20.3, 19.0, 11.0]\n",
    "print('R2 score: {:.3f}'.format(metrics.r2_score(y_true, y_pred).round(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **НЕДОСТАТКИ АНАЛИТИЧЕСКОГО РЕШЕНИЯ**\n",
    "\n",
    "Ранее мы с вами рассмотрели, что такое модель линейной регрессии, и научились рассчитывать её параметры с помощью аналитического подхода — метода наименьших квадратов.\n",
    "\n",
    "![](data\\f36.png)\n",
    "\n",
    "Метод наименьших квадратов позволяет очень просто получить коэффициенты , подставив таблицу в формулу. Вот, собственно, и всё «обучение». \n",
    "\n",
    "→ Существует теорема Гаусса-Маркова, которая говорит о том, что, если выполнены все условия теоремы, МНК всегда находит оптимальные оценки параметров. Мы ещё вернемся к этой теореме, когда будем говорить об МНК в модулях по линейной алгебре.  \n",
    "Казалось бы, относительно простая математика: надо всего лишь перемножить матрицы между собой и получить ответ. Особенно простой эта задача должна быть для компьютера. Но нам так кажется, поскольку мы ранее не сталкивались с матричным умножением и будем говорить о нём только в модулях по линейной алгебре.\n",
    "\n",
    "***Оказывается, у такого простого подхода есть один большой минус — это работа с большим количеством признаков.***\n",
    "\n",
    "Давайте внимательно посмотрим на операцию обращения матриц (возведение в степень -1):\n",
    "\n",
    "![](data\\f37.png)\n",
    "\n",
    "Таблица X имеет размер ***(n,m)***, то есть у неё ***n*** строк и **m** столбцов. Таблица ***XT*** — это результат транспонирования матриц (замены строк и столбцов местами), то есть её размерность — ***(m,n)***. Забегая вперёд, отметим, что по правилам умножения матриц результат умножения будет иметь размерность ***(m,n) x (n,m) = (m,m)***, где ***m*** — это число столбцов.\n",
    "\n",
    "А теперь представим, что у нас не 13 признаков, а 1300. То есть матрица ***Q*** имеет размерность (1300,1300). Но мы делаем вычисления на компьютере, так ведь? Сложностей быть не должно, но... В модулях по линейной алгебре мы увидим, что обращение матриц — очень ресурсозатратная операция. У неё кубическая сложность, то есть если размер матрицы — ***(m,n)***, то на её обращение понадобится ***m^3*** операций. Для нашего примера это 1300^3 = 2197000000!\n",
    "\n",
    "Обращение матриц больших размеров может стать очень трудоёмким процессом при работе с большими объёмами данных.\n",
    "\n",
    "***Второй недостаток МНК — это невозможность инкрементального обучения, или обучения в режиме реального времени.***\n",
    "\n",
    "Что это такое?\n",
    "\n",
    "Представьте, что мы построили модель, но собираемся её уточнять в процессе эксплуатации. К нам приходят всё новые данные, и мы должны изменять параметры модели, подстраиваясь под новые зависимости.\n",
    "\n",
    "Если мы используем метод fit() для модели LinearRegression и передадим в него новые данные, то коэффициенты модели будут рассчитаны по новым данным, а прошлые наблюдения будут забыты. То есть придётся добавлять данные в таблицу и переобучать модель на всех доступных данных ещё раз.\n",
    "\n",
    "Первая и вторая проблемы решаются с помощью замены аналитического МНК на численные методы, такие как градиентный спуск.\n",
    "\n",
    "***Третий недостаток МНК больше теоретический и заключается в том, что матрица ***Q*** в результате вычислений может не существовать. Это связано с математическими особенностями вычисления обратной матрицы, которые мы рассмотрим далее в курсе.***\n",
    "\n",
    "Причина этой проблемы — мультиколлинеарность факторов (сильная корреляционная связь). Из-за этого коэффициенты линейной регрессии становятся слишком большими и модель становится неустойчивой. \n",
    "\n",
    "Проблема решается с помощью регуляризации."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8185abac01d49e395683ec62b5715351e7237a84c5f28c13c545c98638c429dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
