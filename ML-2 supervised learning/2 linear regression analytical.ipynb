{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Линейная регрессия: аналитическое решение**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Регрессия** — это класс задач обучения с учителем, когда по определённому набору признаков объекта необходимо предсказать числовую целевую переменную.\n",
    "\n",
    "Цель обучения — *построить модель, которая бы отражала зависимость между признаками и целевой числовой переменной*.\n",
    "\n",
    "Когда зависимость принимается линейной, такая модель называется **линейной регрессией**.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/7feb9c1039cfe25f8efb02994733047f/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml1-3_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **ОБЩЕЕ ПРЕДСТАВЛЕНИЕ О ЛИНЕЙНОЙ РЕГРЕССИИ**\n",
    "\n",
    "**Линейная регрессия (Linear Regression)** — одна из простейших моделей для решения задачи регрессии. Главная гипотеза состоит в том, что рассматриваемая зависимость является линейной.\n",
    "\n",
    "Общий вид модели в случае, когда целевая переменная зависит от ***m*** факторов, будет иметь следующий вид:\n",
    "\n",
    "![](data\\f1.png)\n",
    "\n",
    "Давайте разбираться, что в этом выражении значит каждая из переменных. Начнём с простого — с двумерного случая."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2D-СЛУЧАЙ**\n",
    "\n",
    "Для начала поговорим о самом простом случае, когда у нас есть один фактор и зависящий от него целевой признак. Геометрически такая зависимость представляет собой координатную плоскость, где мы отмечаем точки по оси x и соответствующие им точки на оси y.\n",
    "\n",
    "*Рассмотрим задачу из нефтяной отрасли. Есть набор данных, где представлены данные о средней пористости скважин (в процентах) и добыче газа на этих скважинах в сутки (в миллионах кубических футов).*\n",
    "\n",
    "Нам бы хотелось построить модель, которая опишет зависимость и позволит по известной пористости скважин предсказывать неизвестную выработку газа.\n",
    "\n",
    "Зависимость целевого признака от фактора представлена на диаграмме рассеяния (см. ниже). Пористость скважины отложена по оси абсцисс — Porosity (%), а добыча газа — по оси ординат, Gas production (Mcf/day).\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5aac4f0c35432b4d259b26227fe41e59/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml2-2_1.png)\n",
    "\n",
    "Из диаграммы отчётливо видно, что с ростом пористости скважины растёт добыча газа. Причём растёт она преимущественно линейно: основная масса точек находится на одной прямой.\n",
    "\n",
    "Идея! Давайте проведём через точки прямую линию так, чтобы она максимально хорошо описывала зависимость.\n",
    "\n",
    "Для этого сначала вспомним уравнение прямой из школьного курса математики:\n",
    "\n",
    "![](data\\f2.png)\n",
    "\n",
    "где:\n",
    "\n",
    "* ***x*** — это некоторый фактор, от которого зависит целевая переменная y. В нашем случае, x — это пористость скважины, а y — добыча газа.\n",
    "* ***k*** — коэффициент наклона прямой (тангенс угла наклона). Если k>0, это означает, что угол наклона прямой острый и прямая возрастает. Если k<0>, угол наклона тупой и прямая убывает.\n",
    "* ***b*** — коэффициент смещения прямой по оси y. Он будет соответствовать значению y при x=0. То есть это точка пересечения прямой и оси Y.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/efff3f61af4a7ba5499bb204d8c61aeb/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml2-2_2.png)\n",
    "\n",
    "На данном графике изображены две прямые с разными коэффициентами наклона. Зелёная прямая соответствует положительному значению k1>0, и геометрически  равен **тангенсу острого угла** a1 наклона прямой по отношению к оси x: k1 = tg(a1). Синяя прямая соответствует отрицательному значению k2<0, и геометрически k2 равен тангенсу тупого угла a2 наклона прямой по отношению к оси x: k2 = tg(a2). Каждая из прямых пересекается с осью y в точках b1 и b2 — это и есть **коэффициент смещения прямых**.\n",
    "\n",
    "Это уравнение и есть двумерная модель линейной регрессии. Зная коэффициенты k и b, мы можем подставить в него любую пористость скважины x и получить предсказание добычи газа y.\n",
    "\n",
    "Однако в машинном обучении приняты немного другие обозначения. Фактическое значение целевой переменной обозначается как y, а вот предсказанное моделью — y^. Также для удобства коэффициенты b и k приведём к единому обозначению: w0 = b и w1 = k. Тогда уравнение модели линейной регрессии запишется в виде:\n",
    "\n",
    "![](data\\f3.png)\n",
    "\n",
    "***Примечание. Коэффициенты w0 и w1 называются параметрами линейной регрессии.***\n",
    "\n",
    "Остаётся только один вопрос: откуда, собственно, взять параметры w0 и w1? Обсудим этот вопрос чуть позже.\n",
    "\n",
    "А пока представим, что параметры мы нашли. В таком случае можно построить прямую, которая опишет нашу зависимость. Пусть коэффициенты составляют (мы их нашли сами по методу наименьших квадратов, о котором поговорим ниже):\n",
    "\n",
    "![](data\\f4.png)\n",
    "\n",
    "Тогда модель будет иметь следующий вид:\n",
    "\n",
    "![](data\\f5.png)\n",
    "\n",
    "Если подставлять значения конкретные значения пористости x в модель, можно построить прямую, которая описывает исходную зависимость. Это и будет графическая интерпретация нашей модели:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/68be2a900a484a12681d3e6d5be5fc3b/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml2-2_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3D-СЛУЧАЙ**\n",
    "\n",
    "Теперь представим, что у нас не один фактор, а два. Например, помимо пористости скважины, мы дополнительно знаем ещё и о её хрупкости в процентах. То есть у нас теперь есть два фактора: ***x1*** — пористость и ***x2*** — хрупкость.\n",
    "\n",
    "Можно отобразить такую зависимость добычи газа от этих факторов в трёхмерном пространстве в виде диаграммы рассеяния:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/241e1620934df4bea3c70cd4d37ac1d7/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml2-2_4.png)\n",
    "\n",
    "В таком случае в выражение для модели добавится ещё одна переменная x2 и соответствующий ей коэффициент w2:\n",
    "\n",
    "![](data\\f6.png)\n",
    "\n",
    "Опять же, представим, что параметры модели мы нашли и они равны:\n",
    "\n",
    "![](data\\f7.png)\n",
    "\n",
    "Тогда модель будет иметь следующий вид:\n",
    "\n",
    "![](data\\f8.png)\n",
    "\n",
    "Это была алгебра — теперь перейдём к геометрии. Геометрически данное уравнение описывает плоскость в трёхмерном пространстве с осями x1 и x2, w0 — смещение плоскости по вертикальной оси, а коэффициенты w1 и w2 — коэффициенты наклона этой плоскости к осям x1 и x2.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5e86dbff46a7bda35c15bf2c88738e67/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml2-2_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ОБЩИЙ СЛУЧАЙ**\n",
    "\n",
    "А что если факторов не два, а больше: 3, 15, 100? Тут-то мы и приходим к общему виду модели линейной регрессии, который вводили в самом начале. Пусть у нас есть ***m*** факторов {x1, x2, ... xm}, от которых зависит целевая переменная y.\n",
    "\n",
    "![](data\\f9.png)\n",
    "\n",
    "В геометрическом смысле данное уравнение описывает плоскость в (m+1)-мерном пространстве (m факторов + 1 целевой признак отложены по осям координат). Такую плоскость называют **гиперплоскостью**.\n",
    "\n",
    "Абстрактное (m+1)-мерное пространство, конечно же, невозможно отобразить графически и сложно даже представить, как оно выглядит. Но нам это и не нужно. Все операции в таком пространстве аналогичны операциям в двумерном или трёхмерном пространстве.\n",
    "\n",
    "Для понимания принципа работы мы будем рассматривать только прямую в двумерном пространстве, а результат уже обобщать на случай с большей размерностью.\n",
    "\n",
    "Стоит отметить, что в DS мы, как правило, работаем с большим количеством факторов (больше двух), которые описывают данные, поэтому отобразить модель в геометрическом пространстве не получится, но важно понимать, что представляет собой сама модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **ПОИСК ПАРАМЕТРОВ ЛИНЕЙНОЙ РЕГРЕССИИ: МЕТОД НАИМЕНЬШИХ КВАДРАТОВ**\n",
    "\n",
    "Теперь мы знаем, как выглядит модель линейной регрессии в общем случае: это простое линейное выражение, подставляя в которое значения факторов, можно найти целевую переменную. Это линейное выражение соответствует прямой, плоскости или гиперплоскости в зависимости от количества признаков.\n",
    "\n",
    "Остаётся вопрос: откуда взять коэффициенты, которые стоят при ***x***?\n",
    "\n",
    "Для ответа на этот вопрос давайте вспомним схему обучения моделей машинного обучения по принципу минимизации эмпирического риска, которую мы рассматривали в предыдущем модуле:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5fac5fe11d423f674949523e3db643c9/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml1-2_1.png)\n",
    "\n",
    "Согласно данной схеме обучения, поиск параметров производится путём ***минимизации некоторой функции ошибки***. Математически мы пытаемся с помощью методов оптимизации найти такие параметры, чтобы ошибка была наименьшей из возможных.\n",
    "\n",
    "Осталось только понять: где взять эту функцию ошибки? Ответ кроется в картинке ниже. Давайте представим, как могла бы выглядеть прямая в двумерном пространстве, проведённая, например, через пять точек:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5fec239cc84df5a5cd29cab48650641d/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml2-2_7.png)\n",
    "\n",
    "* Что вообще есть **ошибка**? В самом простом понимании это расхождение между истиной и предсказанием.\n",
    "\n",
    "Чтобы не учитывать знак расхождения, можно взять модуль разницы между истинным значением и предсказанным (тем, что лежит на прямой). Рассчитать ошибки ei (на рисунке они отмечены красными отрезками) для всех пяти точек можно следующим образом:\n",
    "\n",
    "![](data\\f11.png)\n",
    "\n",
    "где ***yi*** — это результат подстановки i-ого значения x в модель линейной регрессии.\n",
    "\n",
    "Вычислим среднее по всем ошибкам. Такая ошибка называется средняя абсолютная ошибка **(Mean Absolute Error, MAE)** и записывается следующим образом (в двумерном случае):\n",
    "\n",
    "![](data\\f12.png)\n",
    "\n",
    "Осталось только найти такие w0 и w1, при которых MAE была бы минимальной. В математике это записывается следующим образом:\n",
    "\n",
    "![](data\\f13.png)\n",
    "\n",
    "→ Тут-то математики и столкнулись с проблемой. Оказывается, если пытаться решить эту оптимизационную задачу классическими способами (через условия [**экстремума функции**](https://ru.wikipedia.org/wiki/Экстремум)), то поиск решения будет противоречить основным законам математического анализа. Почему? Функция модуля является недифференцируемой в точке 0, то есть не имеет производной. Классическая оптимизационная задача решается через равенство производной функции нулю. Поиск производной может обернуться математическим противоречием.\n",
    "\n",
    "Проблему с MAE можно решить, но всё же она используется гораздо реже.\n",
    "\n",
    "Но математикам, конечно, удалось найти выход. Вместо модуля можно использовать квадрат — он тоже убирает знак ошибки и по сути аналогичен модулю. Получим **среднеквадратичную ошибку (Mean Square Error, MSE)**:\n",
    "\n",
    "![](data\\f14.png)\n",
    "\n",
    "Это и будет наша функция ошибки, которую мы будем минимизировать, управляя параметрами w0 и w1:\n",
    "\n",
    "![](data\\f15.png)\n",
    "\n",
    "*Примечание. В общем случае, когда X — это таблица из ***n*** наблюдений и ***m*** признаков, постановка задачи оптимизации MSE выглядит следующим образом:*\n",
    "\n",
    "![](data\\f16.png)\n",
    "\n",
    "где xij — это значение, которое находится в i-ой строке и j-ом столбце таблицы наблюдений.\n",
    "\n",
    "Математике известно решение данной задачи оптимизации. Метод поиска параметров линейной регрессии называется **методом наименьших квадратов** (сокращённо — МНК) и был изобретён Гауссом ещё в 1795 году. В английской литературе часто можно встретить аббревиатуру OLS (**Ordinary Least Squares**).\n",
    "\n",
    "→ Решать саму задачу поиска минимума функции мы сейчас не будем, так как пока что не владеем достаточными для её решения знаниями о частной производной и условиях экстремума функции многих переменных, но приведём финальный ответ, полученный для общего случая.\n",
    "\n",
    "Итак, пусть у нас есть матрица X, в которой по строкам собрано n наблюдений, а по столбцам отложено m факторов — по сути, это обычный, привычный нам DataFrame. К каждому примеру из таблицы X есть ответ y.\n",
    "\n",
    "Зависимость между факторами и целевым признаком принята линейной, то есть рассматривается обучение модели линейной регрессии:\n",
    "\n",
    "![](data\\f17.png)\n",
    "\n",
    "Мы хотим найти наилучшую оценку для w0, w1, w2, ...,wm.\n",
    "\n",
    "Примечание. Для того чтобы конечная запись формулы была короче и можно было включить в вектор w коэффициент смещения прямой w0, в матрицу X первым добавляют столбец, полностью состоящий из единиц. Это связано со спецификой матричного умножения, о котором мы поговорим далее в курсе.\n",
    "\n",
    "Согласно методу наименьших квадратов, аналитическое выражение для поиска вектора коэффициентов уравнения линейной регрессии имеет вид:\n",
    "\n",
    "![](data\\f18.png)\n",
    "\n",
    "Данная матричная формула позволяет найти неизвестные параметры линейной регрессии в виде вектора w = (w0,w1,w2, ..., wm). Найденные коэффициенты называют **решением задачи линейной регрессии**.\n",
    "\n",
    "Примечание. Верхний индекс T у матрицы X означает транспонирование матриц — смену строк и столбцов местами (поворот таблицы). Пример:\n",
    "\n",
    "![](data\\f19.png)\n",
    "\n",
    "Операция возведения матриц в степень -1 называется обращением матриц. Полученная в результате матрица называется обратной к исходной. Так, матрица (X^T X)^-1 является обратной к матрице X^T X.\n",
    "\n",
    "Саму процедуру обращения матриц мы будем рассматривать в модуле по линейной алгебре. Сейчас же для проведения этой операции мы будем использовать библиотеку numpy, которая позволяет очень быстро и просто обращать матрицы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **АНАЛИТИЧЕСКОЕ РЕШЕНИЕ С ПОМОЩЬЮ NUMPY**\n",
    "\n",
    "Перейдём к практической части. Давайте научимся строить аналитическое решение линейной регрессии по МНК в Python.\n",
    "\n",
    "Вот какие этапы нам предстоит пройти, чтобы построить свою модель:\n",
    "\n",
    "1. Загрузить данные и проанализировать датасет на предмет пропусков.\n",
    "2. Подготовить данные для подачи в модель: избавиться от пропусков, если они есть, и перекодировать категориальные признаки, если они представлены текстом.\n",
    "3. Построить модель. Будем строить несколько моделей линейной регрессии: первую — на одном признаке, вторую — на всех доступных признаках.\n",
    "4. Оценить качество модели.\n",
    "\n",
    "Для начала импортируем необходимые вспомогательные библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') #установка стиля matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем работать с датасетом из библиотеки sklearn о домах в Бостоне. Этот набор данных содержит информацию, собранную службой переписи населения США и касающуюся жилья в районе Бостона, штат Массачусетс.\n",
    "\n",
    "Данный датасет содержится в модуле datasets библиотеки sklearn. Давайте загрузим датасет с помощью функции ***load_boston()*** и выведем его описание, обратившись по ключу ***'DESCR'***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python39\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston \n",
    "boston = load_boston()\n",
    "print(boston['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном описании говорится, что у нас есть 506 участков с жилыми домами, которые описываются 13-ю признаками. На каждом из участков находится несколько домов. Измерены общие показатели по каждому из участков, в том числе медианная стоимость.\n",
    "\n",
    "**Задача — научить модель предсказывать медианную стоимость дома на участке.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
