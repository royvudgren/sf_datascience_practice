{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Собственные векторы и числа**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим, как искать **спектр матрицы** и **собственные числа**.\n",
    "\n",
    "Итак, следующее уравнение должно иметь ненулевые решения:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/11f58101ad93e18af82b71a5882a04ad/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_64.png)\n",
    "\n",
    "Перенесём всё в левую часть уравнения и немного поколдуем:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/8269b545efd5dbf2d71ef0161c7596ed/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_65.png)\n",
    "\n",
    "Конечно, никакой магии здесь нет. Как вы помните, умножение вектора на число — то же самое, что умножение его на скалярную (шаровую) матрицу. Нам это нужно, чтобы можно было честно вынести v за скобку. Так мы получили однородную систему уравнений, у которой всегда будет нулевое решение, но оно нам неинтересно, поскольку нулевые векторы не считаются собственными. Чтобы было ненулевое решение, матрица А – λE должна быть вырождена, то есть её определитель должен быть нулём.\n",
    "\n",
    "*Заметим, что вычитание матрицы λE — это всё равно, что вычитание λ по диагонали матрицы А.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **АЛГОРИТМ ПОИСКА СОБСТВЕННЫХ ВЕКТОРОВ И ЧИСЕЛ НА ПРИМЕРЕ МАТРИЦЫ 2 × 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Записываем характеристическое уравнение:\n",
    "\n",
    "![](data/1.PNG)\n",
    "\n",
    "[**ЗДЕСЬ**](http://www.mathprofi.ru/sobstvennye_znachenija_i_sobstvennye_vektory.html) отличный пример поиска\n",
    "\n",
    "**ПРИМЕР**\n",
    "\n",
    "Найдите собственные числа и собственные вектора матрицы ![](data/2.PNG)\n",
    "\n",
    "Решение:\n",
    "\n",
    "Найдём собственные числа:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5c6b25cbf12a5e772cbc41d9f887eea1/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_67.png)\n",
    "\n",
    "Найдём собственный вектор для λ1 = 1:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/59bf05d9ca9ab10f4f370d32d742b8d2/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_68.png)\n",
    "\n",
    "Решив полученную систему, видим, что векторов v, удовлетворяющих ей, бесконечное множество. Вектор v должен быть ортогонален (1 1). Возьмём:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/4798563055447a4b93f7dbf5ea7c4083/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_69.png)\n",
    "\n",
    "Повторим всё то же самое для λ2 = 4.  Вектор v обозначим за u:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/8550e7a23a87304a6edb8eec44b39b17/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_70.png)\n",
    "\n",
    "Вектор u должен быть ортогонален вектору (1 -2). Возьмём:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/2f1765429202a6f6c3552e8de8f7d83b/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_71.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **КАК ИСКАТЬ ДЛЯ МАТРИЦЫ n × n?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае порядок нахождения собственных чисел и векторов тот же, но:\n",
    "\n",
    "* определитель считается не так просто, как в случае порядка 2;\n",
    "* характеристическое уравнение имеет ту же степень, что и порядок матрицы, т.е. n;\n",
    "* больше собственных чисел → больше вычислений для собственных векторов.\n",
    "***\n",
    "**Свойство спектра матрицы**: произведение собственных чисел равно в точности определителю матрицы.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/1e3f715b4795af2bba7c9f260a8812d5/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_72.png)\n",
    "***\n",
    "\n",
    "**ПРИМЕР**\n",
    "\n",
    "Найдите определитель матрицы ![](data/2.PNG). Как он выражается через спектр?\n",
    "\n",
    "Решение:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/f3d527afa57479d9af32fc85e27b9f45/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_74.png)\n",
    "\n",
    "Давайте теперь поговорим о свойствах спектра и свяжем это понятие с уже знакомыми нам из предыдущего модуля."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **СВОЙСТВА СПЕКТРА**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Все λ > 0 → матрица A **положительно** определена.  \n",
    "    Все λ ≥ 0 → матрица A **НЕотрицательно** определена.  \n",
    "    Все λ < 0 → матрица A **отрицательно** определена.  \n",
    "    Все λ ≤ 0 → матрица A **НЕположительно** определена.  \n",
    "2. det(A) = λ1 · λ2 ·... · λn\n",
    "3. Нулевое собственное число означает вырожденность матрицы.\n",
    "4. Собственные векторы из разных айгенпар, т. е. отвечающие разным собственным значениям, линейно независимы.\n",
    "\n",
    "***\n",
    "* Матрицы с нулевыми или близкими к нулю собственными числами называются **плохо обусловленными**.\n",
    "***\n",
    "Матрица корреляций факторов X и их матрица Грама симметричны и потому обладают рядом крайне полезных свойств.\n",
    "\n",
    "**Свойства симметричных матриц:**\n",
    "\n",
    "1. Полный набор собственных чисел и векторов.\n",
    "2. Если A — матрица Грама, то она неотрицательно определена и даже положительно определена, если её столбцы (регрессионные признаки) линейно независимы.\n",
    "3. Собственные векторы симметричных матриц всегда ортогональны.\n",
    "\n",
    "На этих свойствах работает метод главных компонент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **ОСОБЫЕ СЛУЧАИ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ПРИМЕР**\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/b1132ba8452adff3a43e9162c7a8bd58/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_76.png)\n",
    "\n",
    "Характеристический многочлен матрицы A λ^2 + 1 не имеет вещественных корней. Это значит, что собственных чисел нет, а значит нет и собственных векторов. Это неудивительно: матрица  задаёт поворот вокруг начала координат, и у неё нет неподвижных направлений.\n",
    "\n",
    "**ПРОБЛЕМЫ**\n",
    "\n",
    "1. **Не решается характеристическое уравнение**. Матрица может не иметь вещественных собственных чисел вообще или иметь не полный набор. В анализе факторов регрессий это может значить, что мы выбрали не самый оптимальный алгоритм, и из-за накопившихся вычислительных ошибок матрица перестала быть симметричной. \n",
    "2. **Все собственные числа есть, но из-за особенностей кратности не хватило собственных векторов.** На этой проблеме мы не будем останавливаться.\n",
    "3. **Собственные числа нули или близки к нулю => Плохая обусловленность**. Давайте разберёмся, почему это плохо. Нулевые собственные числа дают нулевой определитель. Здесь всё ясно — обратная матрица к матрице  не существует, и алгоритм вычисления регрессионных коэффициентов по методу OLS рушится. В реальном мире, если матрица  необратима, это говорит о мультиколлинеарности признаков, то есть о линейной зависимости между признаками. Однако ненулевые, но близкие к нулю значения собственных чисел и определителя тоже не сулят ничего хорошего: обратная к плохо обусловленной матрице будет неустойчива. Это значит, что при добавлении одного нового измерения коэффициенты могут измениться очень сильно, и мы не сможем их интерпретировать. Кроме того, будет возникать переобучение регрессии: на обучающей выборке ошибка прогноза будет маленькая, а на тестовой — большая.\n",
    "\n",
    "Бороться с плохой обусловленностью можно с помощью **предварительного отбора признаков**, **метода главных компонент** (Principal Compoment Analysis, PCA) и **сингулярного разложения** (Singular Value Decomposition, SVD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **СПЕКТРАЛЬНОЕ РАЗЛОЖЕНИЕ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у матрицы есть полный набор айгенпар, то у неё есть так называемое спектральное разложение.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/0af464545d53a086f6c68f7ded4b2fea/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MAT_2_unit_77.png)\n",
    "\n",
    "Здесь D — диагональная матрица, на диагонали которой стоят собственные числа A,\n",
    "P — матрица, составленная из собственных векторов, записанных в столбцы. Все векторы записаны в столбцы в том порядке, в котором расположены парные к ним собственные числа в матрице D.\n",
    "\n",
    "Про матрицу A говорят, что она **диагонализуема**, а D — её диагональный вид."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68eacbc5a3a550d9b1f68bf11bf31e2b39ed4b9985227d4d8c7ee1d286013f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
