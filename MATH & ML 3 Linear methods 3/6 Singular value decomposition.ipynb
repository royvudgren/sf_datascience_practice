{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Сингулярное разложение**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь познакомимся с сингулярным разложением (Singular Value Decomposition, SVD).\n",
    "\n",
    "Этот метод используется в большом количестве приложений, и мы нередко будем с ним сталкиваться, например при изучении рекомендательных систем. \n",
    "\n",
    "На самом деле **сингулярное разложение** — это одна из теорем линейной алгебры с большим количеством полезных свойств. \n",
    "***\n",
    "                                                ТЕОРЕМА\n",
    "\n",
    "Любую прямоугольную матрицу A размера (n, m) можно представить в виде произведения трёх матриц:\n",
    "\n",
    "![](data/17.PNG)\n",
    "\n",
    "* U — матрица размера (n, n). Все её столбцы ортогональны друг другу и имеют единичную длину. Такие матрицы называются **ортогональными**.\n",
    "* D — матрица размера (n, m). На её главной диагонали стоят числа, называемые **сингулярными числами**, а вне главной диагонали стоят нули.\n",
    "* V — матрица размера (m, m). Она тоже **ортогональная**.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **КАК ПОЛУЧАЮТСЯ ЭТИ МАТРИЦЫ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](data/18.PNG)\n",
    "\n",
    "✍️ Итак, давайте рассмотрим пример разложения произвольной прямоугольной матрицы.\n",
    "\n",
    "ПРИМЕР\n",
    "\n",
    "Сингулярно разложить матрицу A, если:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/ac4f0f1977c60cbccd6ce480ba22b84f/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-20.png)\n",
    "\n",
    "Решение:\n",
    "\n",
    "Для начала найдём компоненты правой матрицы VT. Для этого составляем матрицу Грама A.T@A:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3d7dac9aaa3ab3568dfc4e38bf98cc11/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-21.png)\n",
    "\n",
    "Следующим шагом находим собственные числа и собственные векторы матрицы A.T@A. Для этого составляем характеристическое уравнение для этой матрицы:\n",
    "\n",
    "![](data/19.PNG)\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/539a567834c41fdd720410e20b498683/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-22.png)\n",
    "\n",
    "Теперь у нас есть всё для того, чтобы составить матрицу VT. Для этого полученные собственные векторы располагаем в столбцах матрицы VT в порядке возрастания их собственных чисел!\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c118ef90fa3ea7aaf921f390cbba453f/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-23.png)\n",
    "\n",
    "* Векторы v1 и v2 называются **правыми сингулярными векторами** матрицы A.\n",
    "\n",
    "Теперь найдём компоненты матрицы U. Для этого составляем матрицу Грама AAT:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/17b41dc7c2df6d1f44e3ca88fa4a0681/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-24.png)\n",
    "\n",
    "Составляем характеристическое уравнение для матрицы AAT, чтобы найти ее собственные значения и собственные числа. Спойлер: ненулевые собственные числа для матриц AAT и ATA всегда будут совпадать:\n",
    "\n",
    "![](data/20.PNG)\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/e7d803b7a37dd3e8f7f1445df9666013/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-26.png)\n",
    "\n",
    "Составляем матрицу U из нормированных векторов u1, u2 и u3, расположив их в столбцах в порядке убывания собственных чисел, соответствующих собственным векторам:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3cb6248a0e961bdb805115335065da48/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-27.png)\n",
    "\n",
    "* Векторы u1, u2 и u3 называются **левыми сингулярными векторами** матрицы A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для составления сингулярного разложения нам с вами осталось найти матрицу D. На её диагонали будут располагаться сингулярные числа, которые вычисляются как квадратные корни из ненулевых собственных чисел:\n",
    "\n",
    "![](data/21.PNG)\n",
    "\n",
    "Полученные сингулярные числа располагаются в матрице D на главной диагонали, оставшиеся строки матрицы заполняются нулями.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/800777b672d3eee75cd5dd9b6e7e300c/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-28.png)\n",
    "\n",
    "Теперь у нас есть все компоненты, чтобы составить сингулярное разложение! \n",
    "\n",
    "Вспоминаем формулу:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/d56affc2714d87ca794ea9b6e0a5bbd0/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-29.png)\n",
    "\n",
    "✍️ Если мы перемножим все полученные матрицы между собой, мы получим изначальную матрицу A! Проверьте это самостоятельно. Проверьте также, что UTU = UUT = E и VTV = VVT = E."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке numpy сингулярное разложение реализовано в функции **np.linalg.svd()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.66666667,  0.66666667, -0.33333333],\n",
       "        [-0.66666667, -0.33333333,  0.66666667],\n",
       "        [ 0.33333333,  0.66666667,  0.66666667]]),\n",
       " array([8.48528137, 4.24264069]),\n",
       " array([[-0.70710678, -0.70710678],\n",
       "        [-0.70710678,  0.70710678]]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# составляем матрицу А \n",
    "A = np.array([\n",
    "    [2, 5, -4],\n",
    "    [6, 3, 0],\n",
    "]).T\n",
    "# применяем сингулярное разложение\n",
    "np.linalg.svd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция возвращает кортеж из трёх массивов:\n",
    "\n",
    "* Левая матрица сингулярного разложения U, состоящая из собственных векторов матрицы AAT.\n",
    "* Сингулярные числа, стоящие на главной диагонали матрицы D.\n",
    "* Правая матрица сингулярного разложения VT, состоящая из собственных векторов матрицы ATA.\n",
    "\n",
    "Кстати, заметьте, что наш результат полностью совпал с результатом сингулярного разложения, вычисленным вручную."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы спросите: а в чём бонусы сингулярного разложения? Была одна матрица, а стало три — зачем такие сложности? \n",
    "\n",
    "Мы коснёмся основных преимуществ, которые имеют значение именно для нас."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **БОНУС №1. УСЕЧЁННОЕ СИНГУЛЯРНОЕ РАЗЛОЖЕНИЕ**\n",
    "\n",
    "**Усечённое сингулярное разложение** — это когда из всех λ выбираются только d первых, самых больших собственных чисел, а остальные кладутся равными нулю. Таким образом, мы отбрасываем незначительную информацию, оставляя только наиболее отличные от 0 собственные числа и собственные вектора.\n",
    "\n",
    "Такой приём очень активно используется, например, в задачах понижения размерности, а также в рекомендательных системах. \n",
    "\n",
    "Предположим, что A — матрица стандартизированных признаков, тогда в строках матрицы VT расположены нужные нам собственные векторы корреляционной матрицы, а на главной диагонали D — корни из собственных чисел корреляционной матрицы.\n",
    "\n",
    "Если мы научимся быстро считать сингулярное разложение, это решит задачу поиска главных компонент.\n",
    "\n",
    "Для этого, во-первых, договоримся в матрице D все диагональные элементы писать так, чтобы левый верхний был самый большой, а правый нижний — самый маленький. Тогда все «большие» сингулярные числа сосредоточатся в левом верхнем углу. И нам будет достаточно вычислить и хранить только его, а остальное заменить нулями.\n",
    "\n",
    "То же касается и матриц U и VT. Если A плохо обусловлена, то «хорошие» собственные векторы корреляционной матрицы будут расположены в верхней части матрицы VT, а остальные будут незначимы и мы сможем заменить их на нули. У матрицы U значимые столбцы будут слева, а справа — незначимые, которые тоже можем обрезать нулевыми.\n",
    "\n",
    "**ПРИМЕР**\n",
    "\n",
    "Пусть у нас есть 10 000 наблюдений по 5 000 признаков.\n",
    "\n",
    "Если данные очень плохо обусловлены и «больших» (не совсем нулевых) собственных чисел всего 10, то мы сможем хранить только небольшие кусочки от всего здорового разложения.\n",
    "\n",
    "10 признаков по 10 000 наблюдений из матрицы U, угол 10 на 10 из матрицы D и первые 10 строк из матрицы VT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **БОНУС №2. РЕШЕНИЕ МНК ЧЕРЕЗ СИНГУЛЯРНОЕ РАЗЛОЖЕНИЕ**\n",
    "\n",
    "Благодаря сингулярному разложению мы можем получить защиту от работы с вырожденными матрицами.\n",
    "\n",
    "Пусть мы решаем задачу регрессии и в качестве модели используем линейную регрессию:\n",
    "\n",
    "![](data/22.PNG)\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3901472afa9fa1670d81d6c983d26454/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-31.png)\n",
    "\n",
    "Чтобы получить решение, мы составляем матрицу наблюдений A, записав в её столбцы все наши регрессоры, включая регрессор-константу:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/2a1541aa5a6285c1c9f8b914476ac969/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-math-ml-3-32.png)\n",
    "\n",
    "Тогда согласно МНК оценка вектора весов w вычисляется по формуле:\n",
    "\n",
    "![](data/23.PNG)\n",
    "\n",
    "Но как мы уже с вами знаем, матрица ATA может быть плохо обусловлена или даже вырождена, что приводит к неустойчивым решениям, либо вовсе невозможности получить решение.\n",
    "\n",
    "* Идея. Давайте представим матрицу наблюдений A в виде сингулярного разложения и посмотрим, что получится.\n",
    "\n",
    "![](data/24.PNG)\n",
    "\n",
    "                формула вычисления МНК-оценки через сингулярное разложение матрицы A\n",
    "***\n",
    "А в чём бонус? Давайте присмотримся внимательно. \n",
    "\n",
    "Если в классической формуле нужно было вычислять обратную матрицу (A.T@A)^-1, которая может быть вырожденной, то в новой формуле мы вычисляем обратную матрицу от диагональной матрицы D^-1. **Диагональная матрица никогда не может быть вырожденной**, у неё **всегда есть обратная**. То есть решение будет существовать всегда, даже при линейно зависимых строках и столбцах!\n",
    "\n",
    "Строго говоря, матрица D не является диагональной, так как в общем случае она прямоугольная. У нее N строк и k столбцов. Однако только k из них являются ненулевыми, остальные заполнены нулями. Поэтому обратная вычисляется от квадратной диагональной матрицы с ненулевыми строками."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **КАК СЧИТАЕТСЯ СИНГУЛЯРНОЕ РАЗЛОЖЕНИЕ?**\n",
    "\n",
    "В реализациях в Python для вычисления сингулярного разложения используются разные итеративные алгоритмы, которые не считают все разложение целиком, а вычисляют постепенно. Подробнее о них вы можете почитать [**здесь**](http://www.machinelearning.ru/wiki/index.php?title=Простой_итерационный_алгоритм_сингулярного_разложения). \n",
    "\n",
    "**ГДЕ ИСПОЛЬЗУЕТСЯ?**\n",
    "\n",
    "SVD-разложение зашито внутри очень многих алгоритмов в Python.\n",
    "\n",
    "* Например, функция **numpy.linalg.rank** использует его, когда считает ранг матрицы. А **numpy.linalg.det** и **numpy.linalg.inv** не используют, поэтому у них получаются неадекватные результаты для плохо обусловленных матриц, а ранг всегда вычисляется верно.\n",
    "* Функция **numpy.linalg.lstsq** вычисляет оценку решения переопределенной системы с помощью МНК. Она тоже работает на SVD и устойчива к плохо обусловленным матрицам.\n",
    "* В sklearn сингулярное разложение зашито внутри класса **LinearRegression**, реализующего модель линейной регрессии по МНК."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68eacbc5a3a550d9b1f68bf11bf31e2b39ed4b9985227d4d8c7ee1d286013f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
