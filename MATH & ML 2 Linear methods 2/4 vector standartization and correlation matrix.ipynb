{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Стандартизация векторов и матрица корреляций**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **СТАНДАРТИЗАЦИЯ ВЕКТОРОВ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В модулях по разведывательному анализу данных и машинному обучению мы не раз говорили о преобразованиях признаков путём нормализации и стандартизации. Вспомним, что это такое\n",
    "***\n",
    "* **Нормализация** — это процесс приведения признаков к единому масштабу, например от 0 до 1. Пример — min-max-нормализация:\n",
    "\n",
    "![](data/31.PNG)\n",
    "\n",
    "* **Стандартизация** — это процесс приведения признаков к единому масштабу характеристик распределения — нулевому среднему и единичному стандартному отклонению:\n",
    "\n",
    "![](data/32.PNG)\n",
    "***\n",
    "\n",
    "В линейной алгебре под стандартизацией вектора ![](data/33.PNG) понимается несколько другая операция, которая проходит в два этапа:\n",
    "\n",
    "1. **Центрирование вектора** — это операция приведения среднего к 0:\n",
    "\n",
    "![](data/34.PNG)\n",
    "\n",
    "2. **Нормирование вектора** — это операция приведения диапазона вектора к масштабу от -1 до 1 путём деления центрированного вектора на его длину:\n",
    "\n",
    "![](data/35.PNG)\n",
    "\n",
    "В результате стандартизации вектора всегда получается новый вектор, длина которого равна 1:\n",
    "\n",
    "![](data/36.PNG)\n",
    "\n",
    "***\n",
    "\n",
    "![](data/37.PNG)  \n",
    "![](data/38.PNG)\n",
    "\n",
    "Как видите, теперь оба признака имеют значения от -1 до 1 и равный порядок, в отличие от исходных признаков.\n",
    "***\n",
    "Давайте посмотрим, что произойдёт с матрицей Грама после стандартизации векторов x1 и x2:\n",
    "\n",
    "![](data/39.PNG)\n",
    "\n",
    "Как видите, все числа — в диапазоне от -1 до 1. \n",
    "***\n",
    "Забегая вперёд, скажем, что это так называемые **выборочные корреляции признаков**, а сама матрица является **матрицей корреляций** или **корреляционной матрицей**. Пока просто запомните, как выглядит эта матрица.\n",
    "\n",
    "![](data/40.PNG)\n",
    "\n",
    "* После стандартизации мы прогоняем регрессию стандартизованного y на стандартизованные регрессоры **без константы**.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В ЧЁМ БОНУСЫ?**\n",
    "\n",
    "Математика говорит, что регрессия исходного y на исходные («сырые») признаки c константой точно такая же, как регрессия стандартизированного на стандартизированные признаки без константы. В чём же разница? Математически — ни в чём.\n",
    "\n",
    "На прогноз модели линейной регрессии, построенной по МНК, и её качество стандартизация практически не влияет. Масштабы признаков будут иметь значение только в том случае, если для поиска коэффициентов вы используете численные методы, такие как градиентный спуск (SGDRegressor из sklearn). О нём мы поговорим, когда будем знакомиться с алгоритмом градиентного спуска в модуле по оптимизации.\n",
    "\n",
    "Однако с точки зрения интерпретации важности коэффициентов разница есть. Если вы занимаетесь отбором наиболее важных признаков по значению коэффициентов линейной регрессии на нестандартизированных данных, это будет не совсем корректно: один признак может изменяться от 0 до 1, а второй — от -1000 до 1000. Коэффициенты при них также будут различного масштаба. Если же вы посмотрите оценки коэффициентов регрессии после стандартизации, то они будут в едином масштабе, что даст более цельную и объективную картину.\n",
    "\n",
    "Более важный бонус заключается в том, что после стандартизации матрица Грама признаков как по волшебству превращается в корреляционную матрицу, о которой пойдёт речь далее. Почему это хорошо? На свойства корреляционной матрицы опираются такие алгоритмы, как метод главных компонент и сингулярное разложение, а так как «сырая» и стандартизированная регрессия математически эквивалентны, то имеет смысл исследовать стандартизированную, а результаты обобщить на «сырую»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим всё это на примере ↓\n",
    "\n",
    "Пример № 3\n",
    "\n",
    "Вновь рассмотрим данные о стоимости жилья в районах Бостона.\n",
    "\n",
    "На этот раз возьмём четыре признака: CHAS, LSTAT, CRIM и RM.\n",
    "\n",
    "Для начала посмотрим на статистические характеристики с помощью метода describe():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roman\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка библиотек\n",
    "import numpy as np # для работы с массивами\n",
    "import pandas as pd # для работы с DataFrame \n",
    "from sklearn import datasets # для импорта данных\n",
    "import seaborn as sns # для визуализации статистических данных\n",
    "import matplotlib.pyplot as plt # для построения графиков\n",
    "\n",
    "# загружаем датасет\n",
    "boston = datasets.load_boston()\n",
    "boston_data = pd.DataFrame(\n",
    "    data=boston.data, #данные\n",
    "    columns=boston.feature_names #наименования столбцов\n",
    ")\n",
    "boston_data['PRICE'] = boston.target\n",
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.069170</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>6.284634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.253994</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>0.702617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>3.561000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>5.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>0.256510</td>\n",
       "      <td>6.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>6.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>8.780000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CHAS       LSTAT        CRIM          RM\n",
       "count  506.000000  506.000000  506.000000  506.000000\n",
       "mean     0.069170   12.653063    3.613524    6.284634\n",
       "std      0.253994    7.141062    8.601545    0.702617\n",
       "min      0.000000    1.730000    0.006320    3.561000\n",
       "25%      0.000000    6.950000    0.082045    5.885500\n",
       "50%      0.000000   11.360000    0.256510    6.208500\n",
       "75%      0.000000   16.955000    3.677083    6.623500\n",
       "max      1.000000   37.970000   88.976200    8.780000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data[['CHAS', 'LSTAT', 'CRIM','RM']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что каждый из признаков измеряется в различных единицах и изменяется в различных диапазонах: например, CHAS лежит в диапазоне от 0 до 1, а вот CRIM — в диапазоне от 0.006 до 88.976.\n",
    "\n",
    "Рассмотрим модель линейной регрессии по МНК без стандартизации. Помним, что необходимо добавить столбец из единиц:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.92052548]\n",
      " [ 3.9975594 ]\n",
      " [-0.58240212]\n",
      " [-0.09739445]\n",
      " [ 5.07554248]]\n"
     ]
    }
   ],
   "source": [
    "# составляем матрицу наблюдений и вектор целевой переменной\n",
    "A = np.column_stack((np.ones(506), boston_data[['CHAS', 'LSTAT', 'CRIM','RM']]))\n",
    "y = boston_data[['PRICE']]\n",
    "# вычисляем OLS-оценку для коэффициентов без стандартизации\n",
    "w_hat=np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот наши коэффициенты. Округлим их для наглядности:\n",
    "\n",
    "![](data/41.PNG)\n",
    "\n",
    "Давайте вспомним интерпретацию коэффициентов построенной модели линейной регрессии, которую мы изучали в модуле «ML-2. Обучение с учителем: регрессия». Значение коэффициента wi означает, на сколько в среднем изменится медианная цена (в тысячах долларов) при увеличении xi на 1.\n",
    "\n",
    "Например, если количество низкостатусного населения (LSTAT) увеличится на 1 %, то медианная цена домов в районе (в среднем) упадёт на 0.6 тысяч долларов. А если среднее количество комнат (RM) в районе станет больше на 1, то медианная стоимость домов в районе (в среднем) увеличится на 5 тысяч долларов. \n",
    "***\n",
    "*Тут в голову может прийти мысль: судя по значению коэффициентов, количество комнат (RM) оказывает на стоимость жилья большее влияние, чем процент низкостатусного населения (LSTAT). Однако такой вывод будет ошибочным. Мы не учитываем, что **признаки, а значит и коэффициенты линейной регрессии, лежат в разных масштабах**. Чтобы говорить о важности влияния признаков на модель, нужно строить её на стандартизированных данных.*\n",
    "***\n",
    "**Помним, что для построения стандартизированной линейной регрессии нам не нужен вектор свободных коэффициентов, а значит и столбец из единиц тоже не понадобится.**\n",
    "\n",
    "Сначала центрируем векторы, которые находятся в столбцах матрицы A. Для этого вычтем среднее, вычисленное по строкам матрицы A в каждом столбце, с помощью метода mean(). Затем разделим результат на длины центрированных векторов, вычисленных с помощью функции linalg.norm().\n",
    "\n",
    "Примечание. Обратите внимание, что для функции linalg.norm() обязательно необходимо указать параметр axis=0, так как по умолчанию норма считается для всей матрицы, а не для каждого столбца в отдельности. С определением нормы матрицы и тем, как она считается, вы можете ознакомиться в [**документации к функции norm().**](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CHAS   LSTAT    CRIM      RM\n",
       "count  506.00  506.00  506.00  506.00\n",
       "mean    -0.00   -0.00   -0.00   -0.00\n",
       "std      0.04    0.04    0.04    0.04\n",
       "min     -0.01   -0.07   -0.02   -0.17\n",
       "25%     -0.01   -0.04   -0.02   -0.03\n",
       "50%     -0.01   -0.01   -0.02   -0.00\n",
       "75%     -0.01    0.03    0.00    0.02\n",
       "max      0.16    0.16    0.44    0.16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# составляем матрицу наблюдений без дополнительного столбца из единиц\n",
    "A = boston_data[['CHAS', 'LSTAT', 'CRIM','RM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# стандартизируем векторы в столбцах матрицы A\n",
    "A_cent = A - A.mean()\n",
    "A_st = A_cent/np.linalg.norm(A_cent, axis=0)\n",
    "A_st.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь векторы имеют одинаковые средние значения и стандартные отклонения. Если вычислить длину каждого из векторов, мы увидим, что они будут равны 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(A_st, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения стандартизированных коэффициентов нам также понадобится стандартизация целевой переменной  по тому же принципу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стандартизируем вектор целевой переменной\n",
    "y_cent = y - y.mean()\n",
    "y_st = y_cent/np.linalg.norm(y_cent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формула для вычисления коэффициента та же, что и раньше, только матрица A теперь заменяется на Ast, а y — на yst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11039956]\n",
      " [-0.45220423]\n",
      " [-0.09108766]\n",
      " [ 0.38774848]]\n"
     ]
    }
   ],
   "source": [
    "# вычислим OLS-оценку для стандартизированных коэффициентов\n",
    "w_hat_st=np.linalg.inv(A_st.T@A_st)@A_st.T@y_st\n",
    "print(w_hat_st.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вновь смотрим на коэффициенты. Помним, что коэффициента w0 у нас больше нет:\n",
    "\n",
    "![](data/42.PNG)\n",
    "\n",
    "Однако теперь интерпретировать сами коэффициенты в тех же измерениях у нас не получится.\n",
    "***\n",
    "**Сделаем важный вывод ↓**\n",
    "\n",
    "Для того чтобы проинтерпретировать оценки коэффициентов линейной регрессии (**понять, каков будет прирост целевой переменной при изменении фактора на 1 условную единицу**), нам достаточно построить линейную регрессию в обычном виде без стандартизации и получить обычный вектор w.\n",
    "\n",
    "Однако, чтобы корректно говорить о том, **какой фактор оказывает на прогноз большее влияние**, необходимо рассматривать стандартизированную оценку вектора коэффициентов wst.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.091251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.053929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.613808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.219247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CHAS     LSTAT      CRIM        RM\n",
       "CHAS   1.000000 -0.053929 -0.055892  0.091251\n",
       "LSTAT -0.053929  1.000000  0.455621 -0.613808\n",
       "CRIM  -0.055892  0.455621  1.000000 -0.219247\n",
       "RM     0.091251 -0.613808 -0.219247  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Давайте поближе взглянем на матрицу Грама для стандартизированных факторов:\n",
    "\n",
    "# матрица Грама\n",
    "A_st.T @ A_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле мы с вами только что вычислили **матрицу выборочных корреляций** наших исходных факторов. Мы уже сталкивались с ней много раз в разделах по разведывательному анализу данных и машинному обучению, правда, вычисляли её мы с помощью функции Pandas, а теперь научились делать это вручную.\n",
    "\n",
    "Примечание. Матрицу корреляций можно получить только в том случае, если производить стандартизацию признаков как векторы (делить на длину центрированного вектора xst). Другие способы стандартизации/нормализации признаков не превращают матрицу Грама в матрицу корреляций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([12,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.707, -0.707])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Стандартизируйте вектор x = (12,8), приведя его к единичной длине.\n",
    "# В качестве ответа введите координаты полученного вектора.\n",
    "# Ответ округлите до третьего знака после точки-разделителя.\n",
    "\n",
    "x = np.array([12,8])\n",
    "\n",
    "x_cent = x - x.mean()\n",
    "x_st = (x_cent/np.linalg.norm(x_cent)).round(3)\n",
    "x_st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **КОРРЕЛЯЦИОННАЯ МАТРИЦА**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Напомним, что **корреляционная матрица** ***C*** — это матрица выборочных корреляций между факторами регрессий.\n",
    "***\n",
    "![](data/43.PNG)\n",
    "\n",
    "Корреляция является одной из важнейших статистических характеристик выборки. Как мы уже знаем из модуля «EDA-2. Математическая статистика в контексте EDA», корреляцию можно измерять различным способами:\n",
    "\n",
    "* корреляцией **Пирсона**;\n",
    "* корреляцией **Спирмена**;\n",
    "* корреляцией **Кендалла**.\n",
    "\n",
    "В этом модуле мы будем говорить именно о **корреляции Пирсона**. Она измеряет тесноту линейных связей между непрерывными числовыми факторами и может принимать значения от -1 до +1.\n",
    "\n",
    "![](data/44.PNG)\n",
    "\n",
    "Как и любая статистическая величина, корреляция бывает **генеральной** и **выборочной**. Разница очень тонкая, и мы подробнее разберём её в модуле по теории вероятностей.\n",
    "***\n",
    "* **Генеральная (истинная) корреляция** — это теоретическая величина, которая отражает общую линейную зависимость между случайными величинами Xi и Xj. Забегая вперёд скажем, что данная характеристика является абстрактной и вычисляется для **генеральных совокупностей** — всех возможных реализаций Xi и Xj. В природе такой величины не существует, она есть только в теории вероятностей.\n",
    "* **Выборочная корреляция** — это корреляция, вычисленная на ограниченной выборке. Это уже ближе к нашей теме. Выборочная корреляция отражает линейную взаимосвязь между факторами xi и xj, реализации которых представлены в выборке.\n",
    "***\n",
    "\n",
    "Выборочная корреляция между факторами высчитывается по громоздкой (на первый взгляд) формуле:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/d4967fe68e49e8466304c6b2a1e5fc14/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_14.png)\n",
    "\n",
    "Из вычисленных cij как раз и составляется матрица корреляций C. Если факторов k штук, то матрица C будет квадратной размера dimC = (k,k):\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/7c5025940975cb81148929005d8dfe5e/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_15.png)\n",
    "\n",
    "Давайте разберём представленную выше формулу на простом примере. Но сначала нас вновь будут ждать довольно сложные формулы — не пугайтесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример № 1\n",
    "\n",
    "Найти выборочную корреляцию факторов:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/64694adccb1ace615100228420e63845/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_16.png)\n",
    "\n",
    "Смотрим на формулу для выборочной корреляции. Чтобы вычислить коэффициент корреляции c12, необходимо предварительно вычислить x1mean и x2mean — средние значения координат векторов.\n",
    "\n",
    "Мы уже вычисляли их ранее:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/a6655c1b4001ddda5f07fca742039bf3/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_17.png)\n",
    "\n",
    "Далее нужно вычислить числитель:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/6ada8b8a6da887327878d01993ed127a/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_18.png)\n",
    "\n",
    "Если присмотреться, можно заметить не что иное, как скалярное произведение векторов (x1-x1mean) и (x2-x2mean). Считаем:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/78925ad0f36b1a82d15a62f682f0a059/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_19.png)\n",
    "\n",
    "Кажется, мы это уже где-то видели. Да — это векторы x1cent и x2cent, которые мы получили, когда стандартизировали векторы. Посчитаем их скалярное произведение:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/3b9787f952f2b515ab9d324c90300871/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_20.png)\n",
    "\n",
    "А что в знаменателе?\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5e3fa77b5e9840899c93b5057c8e4ac4/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_21.png)\n",
    "\n",
    "Это произведение длин векторов x1cent и x2cent.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/a5644ce19365c79e89b4dfc9ab50ec4d/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_22.png)\n",
    "\n",
    "Мы также уже считали их в примере по стандартизации:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/26a98091216e3764b944108cd72430f6/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_23.png)\n",
    "\n",
    "Считаем коэффициент корреляции:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/122346e6575847f6e6a5b329909b4f7f/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_24.png)\n",
    "\n",
    "Снова знакомые числа. Да — это элемент на побочной диагонали матрицы Грама, вычисленной для стандартизированных векторов x1cent и x2cent, а значит:\n",
    "\n",
    "![](data/45.PNG)\n",
    "***\n",
    "*Если посчитать корреляцию в обратном порядке между факторами c21 = (x2st, x1st), получим то же самое число, ведь скалярное произведение перестановочно: c12 = c21.*\n",
    "\n",
    "*Ещё один очевидный факт → Корреляция фактора с самим собой всегда равна 1: cii = 1, то есть c11 = c22 = 1. Так происходит потому, что скалярное произведение вектора с самим собой всегда даёт 1 по свойствам скалярного произведения.*\n",
    "***\n",
    "\n",
    "Вот мы и нашли нашу матрицу корреляций:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/fe38a8cfceea17039b54d7a668139a79/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_25.png)\n",
    "\n",
    "Она в точности совпадает с матрицей Грама, вычисленной для стандартизированных векторов x1st и x2st:\n",
    "\n",
    "![](data/46.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Геометрическая интерпретация корреляции**\n",
    "\n",
    "Это косинус угла между центрированными векторами xicent и xjcent. По свойству скалярного произведения:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/b8a0bb72498df265b1163785689d541f/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Решение на PYTHON**\n",
    "\n",
    "В NumPy матрица корреляций вычисляется функцией **np.corrcoef()**:\n",
    "\n",
    "Получили тот же результат, что и раньше.\n",
    "\n",
    "В Pandas матрица корреляций вычисляется методом **corr()**, вызванным от имени DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.18898224],\n",
       "       [-0.18898224,  1.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = np.array([1, 2, 6])\n",
    "x_2 = np.array([3000, 1000, 2000])\n",
    "np.corrcoef(x_1, x_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике корреляция с точки зрения линейной алгебры означает следующее:\n",
    "\n",
    "* Если корреляция cij = **1**, значит векторы xi и xj **пропорциональны и сонаправлены**.\n",
    "* Если корреляция cij = **-1**, значит векторы xi и xj п**ропорциональны и противонаправлены**.\n",
    "* Если корреляция cij = **0**, значит векторы xi и xj **ортогональны друг другу** и, таким образом, являются **линейно независимыми**.\n",
    "\n",
    "Во всех остальных случаях между факторами xi и xj существует какая-то линейная взаимосвязь, причём чем ближе модуль коэффициента корреляции к 1, тем сильнее эта взаимосвязь. Вспомним классификацию связей факторов, которую мы рассматривали в модуле «EDA-2. Математическая статистика в контексте EDA»:\n",
    "\n",
    "![](data/47.PNG)\n",
    "\n",
    "***\n",
    "Промежуточный вывод ↓  \n",
    "Таким образом, **матрица корреляций — это матрица Грама**, составленная для стандартизированных столбцов исходной матрицы наблюдений A. Она всегда (в теории) симметричная. На главной диагонали этой матрицы стоят 1, а на местах всех остальных элементов — коэффициенты корреляции между факторами xi и xj.\n",
    "\n",
    "Если коэффициент корреляции больше 0, то взаимосвязь между факторами прямая (растёт один — растёт второй), в противном случае — обратная (растёт один — падает второй).\n",
    "***\n",
    "\n",
    "![](data/48.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример № 3\n",
    "\n",
    "Давайте посмотрим на корреляционную матрицу в задаче прогнозирования количества показов квартир агентства недвижимости «Рай в шалаше» в зависимости от разных параметров.\n",
    "\n",
    "Здесь:\n",
    "\n",
    "* Demo 2 w — количество показов квартир за две недели;\n",
    "* Rub — стоимость аренды в рублях;\n",
    "* Area — площадь квартиры;\n",
    "* Liv.Area — жилая площадь квартиры;\n",
    "* Floor — этаж;\n",
    "* Euro — стоимость аренды в евро;\n",
    "* NLiv.Area — нежилая площадь квартиры.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/bb23d029a87a3d7bea81868f09ea72ad/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица получилась размером 7x7, однако её ранг равен 5, а определитель — и вовсе 0. Что это значит? Для начала заметим, что по главной диагонали матрицы стоят единицы — это корреляция каждого фактора с самим собой. Разумеется, матрица симметрична: в первой строке и первом столбце расположены корреляции целевого параметра, то есть количества показов со всеми остальными факторами. Чем эти корреляции больше, тем сильнее взаимосвязь факторов.\n",
    "\n",
    "Подозрительно одинаковыми выглядят корреляции со стоимостью аренды в рублях и евро. Корреляция между ними равна 1. Это логично так как факторы пропорциональны с каким-то коэффициентом. Кроме того, также странно велика корреляция между жилой и общей площадью. Чистой пропорциональности здесь нет, но из предыдущего модуля мы помним, что жилая, нежилая и общая площади линейно зависимы.\n",
    "\n",
    "Обратите внимание, что корреляции с нежилой площадью не так велики. Итого мы нашли два избыточных набора факторов: один набор пропорционален, другой просто линейно зависим. Это случай чистой коллинеарности. Уберём по одному фактору из каждого, и ранг станет максимальным. \n",
    "\n",
    "Нежилая площадь имеет самую маленькую корреляцию с целевым параметром, поэтому мы избавимся от неё.\n",
    "\n",
    "Между рублями и евро нет разницы — оставим рубли, так как они нам привычнее.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/ec9dfbd4d4053051f434998bc27a1e8f/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_29.png)\n",
    "\n",
    "Итак, мы избавились от нежилой площади и аренды в евро. Ранг стал максимальным (то есть равным 5), чистой коллинеарности больше нет, но определитель всё равно маловат. В чём же дело?\n",
    "\n",
    "Стоимость аренды жилой площади и общей площади сильно коррелируют между собой. Обратите внимание на значения коэффициентов корреляции — они практически равны 1, хотя формально эти факторы линейно независимы. Такие корреляции ощутимо портят картину, что и отражается на определителе.\n",
    "\n",
    "Давайте оставим только жилую площадь, её корреляция с показами максимальна.\n",
    "\n",
    "Корреляции между жилой площадью и этажом уже не такие сильные.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/1aaa706a52c33da7f8fd3e77db3ff27d/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md2_4_30.png)\n",
    "\n",
    "Ранг матрицы теперь равен 3 (как ему и положено), а определитель не так близок к нулю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резюмируем ↓\n",
    "\n",
    "![](data/49.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **КАК ОБНАРУЖИТЬ МУЛЬТИКОЛЛИНЕАРНОСТЬ?**\n",
    "\n",
    "* Иногда видно сразу или заметно по **контексту**, что некоторые факторы будут коррелировать между собой.\n",
    "* Также можно посмотреть на **определитель** матрицы корреляции: если он близок к нулю, значит дела обстоят не очень хорошо.\n",
    "* Важным маркером будут странные результаты стандартной регрессионной формулы, например слишком большие по модулю **коэффициенты** (вспомните модуль «ML-2. Обучение с учителем: регрессия», где у нас получились запредельные коэффициенты при решении задач) или взаимно обратные коэффициенты (как мы видели в примере в предыдущем юните). \n",
    "* И, наконец, исследование **спектра** матрицы корреляций и числа обусловленности не только позволяет обнаружить мультиколлинераность, но и помогает избавиться от неё.\n",
    "***\n",
    "Есть много способов борьбы с мультиколлинеарностью. Мы с вами применили самый наивный — удаление взаимных факторов «на глаз». Увы, это получается не всегда.\n",
    "\n",
    "Два других метода называются по-разному, но по сути делают одно и тоже: это **метод главных компонент** для корреляционной матрицы и **сингулярное разложение** матрицы факторов. О них мы поговорим в следующем модуле. \n",
    "\n",
    "Кроме того, можно воспользоваться знакомыми нам методами **регуляризации**, о которых поговорим уже в этом модуле."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **В ЧЁМ ПРОБЛЕМА МУЛЬТИКОЛЛИНЕАРНОСТИ ДЛЯ LINEAR REGRESSION?**\n",
    "\n",
    "Несмотря на то что мультиколлинеарность делает матрицу корреляций более вырожденной, она не оказывает прямого влияния на точность модели сама по себе. Проблема полной вырожденности матрицы (A.T*A), как мы уже обсуждали ранее, в sklearn вполне решается с помощью сингулярного разложения. То есть решение можно получить всегда даже при полной коллинеарности и сильной мультиколлинеарности, несмотря на противоречие с теорией линейной алгебры.\n",
    "\n",
    "\n",
    "Однако сможем ли мы доверять такому решению?\n",
    "\n",
    "Бывают задачи, где важно не просто построить модель, но и проинтерпретировать её результат — коэффициенты линейной регрессии. Типичный пример — задача кредитного скоринга: в ней важно понять, что влияет на вероятность дефолта заёмщика.\n",
    "\n",
    "***\n",
    "\n",
    "Проблема заключается в том, что в случае мультиколлинеарности коэффициенты линейной регрессии становятся неустойчивыми. Например, признак «остаток долга/сумма выдачи» вроде бы должен приводить к уменьшению вероятности дефолта, так как клиенту остаётся выплачивать всё меньшую сумму. Однако мультиколлинеарность приводит к тому, что подобранный в ходе обучения модели коэффициент может сменить знак на противоположный, а признак, с точки зрения модели, может начать говорить об обратном: чем меньше остаётся платить, тем больше вероятность дефолта. Подобный кейс хорошо описан в [**этой**](https://habr.com/ru/company/akbarsdigital/blog/592493/) статье — рекомендуем с ней ознакомиться.\n",
    "\n",
    "К тому же, чем больше в данных мультиколлинеарных факторов, тем сильнее увеличивается разброс коэффициентов регрессии. Полная коллинеарность означает, что существует бесконечное количество способов выразить один фактор через линейную комбинацию других. В свою очередь это значит, что есть бесконечное число возможных коэффициентов регрессии , таких, которые дают одни и те же результаты. \n",
    "\n",
    "Чем больше высококоррелированных факторов в данных, тем больше таких линейных комбинаций и тем больше коэффициенты становятся по модулю, что приводит к проблеме под названием «взрывной рост весов», когда коэффициенты регрессии начинают стремиться к бесконечности, что приводит к «поломке» даже устойчивой к вырожденным матрицам модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 0.05],\n",
       "       [0.05, 1.  ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычислите коэффициент корреляции между векторами v = (5,1,2) и u = (4,2,8).\n",
    "\n",
    "x_1 = np.array([5, 1, 2])\n",
    "x_2 = np.array([4, 2, 8])\n",
    "np.corrcoef(x_1, x_2).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составьте корреляционную матрицу для системы векторов:\n",
    "\n",
    "x1 = 5.1,1.8,2.1,10.3,12.1,12.6  \n",
    "x2 = 10.2,3.7,4.1,20.5,24.2,24.1  \n",
    "x3 = 2.5,0.9,1.1,5.1,6.1,6.3  \n",
    "\n",
    "Для расчёта используйте библиотеку NumPy или Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Чему равен ранг полученной корреляционной матрицы?\n",
    "\n",
    "x1 = np.array([5.1,1.8,2.1,10.3,12.1,12.6])\n",
    "x2 = np.array([10.2,3.7,4.1,20.5,24.2,24.1])\n",
    "x3 = np.array([2.5,0.9,1.1,5.1,6.1,6.3])\n",
    "A_corr = np.corrcoef([x1, x2,x3])\n",
    "np.linalg.matrix_rank(A_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5e-07"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Чему равен определитель полученной корреляционной матрицы?\n",
    "# Ответ округлите до седьмого знака после точки-разделителя.\n",
    "\n",
    "np.linalg.det(A_corr).round(7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68eacbc5a3a550d9b1f68bf11bf31e2b39ed4b9985227d4d8c7ee1d286013f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
