{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Библиотека BeautifulSoup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для поиска необходимых нам данных мы будем использовать библиотеку [**BeautifulSoup**](https://www.crummy.com/software/BeautifulSoup/bs4/doc.ru/), которая позволяет по названию тегов и их атрибутов получать содержащийся в них текст.\n",
    "\n",
    "BeautifulSoup не является частью стандартной библиотеки, поэтому для начала её нужно установить. Например, в Jupyter Notebook это делается с помощью такой команды:\n",
    "\n",
    "**pip install beautifulsoup4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "# Импортируем библиотеку requests\n",
    "import requests\n",
    "from pprint import pprint\n",
    "# Импортируем библиотеку BeautifulSoup\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем извлекать данные из любой веб-страницы.\n",
    "\n",
    "Ранее мы уже получили содержимое страницы с помощью *GET-запроса* и сохранили информацию в переменной *response*, теперь создадим объект *BeautifulSoup* с именем page, указывая в качестве параметра *html.parser*.\n",
    "\n",
    "Для примера получим информацию o title (с англ. заголовок) — это строка, которая отображается на вкладке браузера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей</title>\n",
      "Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей\n"
     ]
    }
   ],
   "source": [
    "url = 'https://nplus1.ru/news/2021/10/11/econobel2021' # Определяем адрес страницы\n",
    "response = requests.get(url) # Выполняем GET-запрос, содержимое ответа присваивается переменной response\n",
    "page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup, указывая html-парсер\n",
    "print(page.title) # Получаем тег title, отображающийся на вкладке браузера\n",
    "print(page.title.text) # Выводим текст из полученного тега, который содержится в атрибуте text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **ИЗВЛЕКАЕМ ЗАГОЛОВОК И ВРЕМЯ НАПИСАНИЯ СТАТЬИ**\n",
    "***\n",
    "Выполним поставленную ранее задачу: получить информацию о [странице](https://nplus1.ru/news/2021/10/11/econobel2021) и извлечь заголовок статьи, опубликованной на этой странице, дату публикации, а также текст статьи.\n",
    "\n",
    "Предположим, что мы знаем, что в HTML-коде рассматриваемой нами страницы заголовок статьи заключён в тег < h1> … < /h1> (заголовок первого уровня).\n",
    "\n",
    "Тогда мы можем получить его текст с помощью метода **find()** (с англ. найти) объекта BeautifulSoup, передав ему название интересующего нас тега:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Премию Нобеля по экономике присудили за исследования экономики труда и причинно-следственных связей\n"
     ]
    }
   ],
   "source": [
    "# Применяем метод find() к объекту и выводим результат на экран\n",
    "print(page.find('h1').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но как же узнать, в каких именно тегах заключена необходимая информация?\n",
    "\n",
    "Проще всего это сделать с помощью так называемого **инструмента разработчика**, который есть во всех современных браузерах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "13:04\n",
      "11 Окт. 2021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Выводим на экран содержимое атрибута text тега time\n",
    "print(page.find('time').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating system\n"
     ]
    }
   ],
   "source": [
    "# Напишите функцию wiki_header, которая по адресу страницы возвращает заголовок для статей на Wikipedia.\n",
    "def wiki_header(url):\n",
    "    response = requests.get(url)\n",
    "    page = BeautifulSoup(response.text, 'html.parser')\n",
    "    title = page.find('h1').text\n",
    "    return title\n",
    "\n",
    "print(wiki_header('https://en.wikipedia.org/wiki/Operating_system'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **НЕУНИКАЛЬНЫЕ ТЕГИ: ИЗВЛЕКАЕМ ТЕКСТ СТАТЬИ**\n",
    "***\n",
    "Теперь получим сам текст статьи. Как вы уже знаете, первым делом необходимо определить, в какой тег он заключён. Применим, как и ранее, инструмент разработчика.\n",
    "\n",
    "![инструмент разработчика](https://lms.skillfactory.ru/assets/courseware/v1/49225813b65e51e70260b9d907fc1bc3/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/Python_17_12.jpg)\n",
    "\n",
    "Видим, что искомый текст заключён в тег  < div> … < /div> . Попробуем извлечь его уже известным нам способом — с помощью метода **find()** — и выведем его на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Выводим содержимое атрибута text тега div\n",
    "print(page.find('div').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы увидели не то, что ожидали — пустое содержимое...\n",
    "\n",
    "Дело в том, что теги **< div> … < /div>** очень распространённые и на странице их очень много. Метод **find()** нашёл первый из них, но это не то, что нам надо.\n",
    "\n",
    "Посмотрим на нашу страницу, используя инструмент разработчика, ещё раз. Можем заметить, что у искомого текста есть свой класс — **body js-mediator-article**:\n",
    "\n",
    "![свой класс](https://lms.skillfactory.ru/assets/courseware/v1/b62dab1aaa4273c5e47d40ff8cb4bdb1/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/Python_17_14.jpg)\n",
    "\n",
    "Передадим название класса в метод find() с помощью аргумента **class_** и получим текст статьи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Премия Шведского национального банка по экономическим наукам памяти Альфреда Нобеля за 2021 год присуждена Дэвиду Карду (David Card) за его вклад в эмпирические исследования экономики рынка труда, а также Джошуа Энгристу (Joshua Angrist) и Гвидо Имбенсу (Guido Imbens) за их вклад в методологию анализа причинно-следственных связей. Прямая трансляция церемонии объявления лауреатов шла на официальном сайте Нобелевской премии.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Слева направо: Дэвид Карт, Джошуа Энгрист и Гвидо Имбенс.\n",
      "Niklas Elmehed © Nobel Prize Outreach\n",
      "\n",
      "\n",
      "\n",
      "Поделиться\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Премия по экономике, в отличие от Нобелевских премий по физиологии и медицине, физике, химии и литературе, а также премии мира, была учреждена не самим Альфредом Нобелем, а Банком Швеции в 1968 году. Ее размер равен размеру остальных премий.Лауреаты этого года награждены за их исследования причинно-следственных связей в области социальных наук. В частности, Дэвид Кард из университета Калифорнии в Беркли начиная с 1990-х годов исследовал, как именно на рынок труда влияют изменения минимальных зарплат, уровень иммиграции и образовательный уровень населения. Полученные им результаты, в частности, указывали, что повышение уровня минимальных зарплат не обязательно влечет за собой сокращение количества рабочих мест.Два других лауреата - Джошуа Ангрист из Массачусетского технологического института и Гвидо Имбенс из Стэнфордского университета исследовали, как можно установить наличие причинно-следственных связей в естественных экспериментах, связанных с поисками отношения между уровнем образования и доходами.Компания Clarivate, которая составляет списки потенциальных нобелевских лауреатов на основе наукометрических данных, в 2021 году предположила, что в экономической номинации премию могут присудить Дэвиду Одречу (David Audretsch) и Дэвиду Тису (David Teece) за исследование инноваций.\n",
      "Кроме того, в списке этого года были Джоэл Мокир (Joel Mokyr), который исследует культурные истоки промышленной революции, а также Кармен Рейнхарт (Carmen Reinhart) и Кеннет Рогофф (Kenneth Rogoff) — авторы гипотезы «90-процентного порога»., согласно которой, когда внешний долг государства достигает 90 процентов от ВВП, скорость роста ВВП падает вдвое.\n",
      "В 2020 году премию по экономике присудили Полу Милгрому и Роберту Уилсону за развитие теории аукционов и изобретение новых форматов аукционов. Лауреаты исследовали, как работают аукционы, и разрабатывали новые форматы проведения аукционов для продажи товаров и услуг, которые трудно продавать с помощью традиционных методов. Читайте об их работах в нашем материале «Тонкости молотка».\n",
      "В 2019 году премии памяти Нобеля по экономике были удостоены Абхиджит Банерджи, Эстер Дюфло и Майкл Кремер — «за экспериментальный подход к искоренению глобальной бедности». Подробнее о заслугах лауреатов можно прочесть в нашем материале «Опыты на бедных». В 2018 года награда была присуждена Уильяму Нордхаусу за «интеграцию изменения климата в долгосрочный макроэкономический анализ» и Полу Ромеру за «интеграцию технологических инноваций в долгосрочный макроэкономический анализ». Об их работах можно прочитать в материале «Почем знания для природы».\n",
      "Сергей Кузнецов\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Выводим содержимое атрибута text тега div класса body js-mediator-article\n",
    "print(page.find('div', class_='body js-mediator-article').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **СБОР НЕСКОЛЬКИХ ЭЛЕМЕНТОВ: СОБИРАЕМ ВСЕ ССЫЛКИ НА СТРАНИЦЕ**\n",
    "***\n",
    "Рассмотрим ещё один сценарий: вы хотите собрать сразу несколько элементов со страницы. Например, представьте, что вы хотите получить названия всех языков программирования, упомянутых на странице в Wikipedia в [**статье**](https://en.wikipedia.org/wiki/List_of_programming_languages) про языки программирования.\n",
    "\n",
    "Можно заметить, что все названия языков программирования на этой странице связаны ссылками c соответствующими статьями о них. Таким образом, нам необходимо собрать все ссылки на странице. Для ссылок в HTML предусмотрен тег **< a> … < /a>**. Попробуем использовать find():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a id=\"top\"></a>\n"
     ]
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_programming_languages' # Задаём адрес ресурса\n",
    "response = requests.get(url) # Делаем GET-запрос к ресурсу\n",
    "page = BeautifulSoup(response.text, 'html.parser') # Создаём объект BeautifulSoup\n",
    "print(page.find('a')) # Ищем ссылку по тегу <a> и выводим её на экран"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили только одну ссылку, хотя на странице их явно больше.\n",
    "\n",
    "Это происходит, потому что метод find() возвращает только первый подходящий элемент. Если требуется получить больше элементов, необходимо воспользоваться методом **find_all()** (с англ. найти все):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939\n"
     ]
    }
   ],
   "source": [
    "links = page.find_all('a') # Ищем все ссылки на странице и сохраняем в переменной links в виде списка\n",
    "print(len(links)) # Выводим количество найденных ссылок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Opal', 'Open Programming Language', 'OpenCL', 'OpenEdge Advanced Business Language', 'OpenVera', 'OpenQASM', 'OPS5', 'OptimJ', 'Orc', 'ORCA/Modula-2']\n"
     ]
    }
   ],
   "source": [
    "print([link.text for link in links[500:510]]) # Выводим ссылки с 500 по 509 включительно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не все ссылки соответствуют названиям языков программирования — страница содержит также «служебные» ссылки, такие, например, как Jump to navigation (с англ. Перейти к навигации) или Alphabetical (с англ. По алфавиту):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'Jump to navigation', 'Jump to search', 'Programming languagelists', 'Alphabetical', 'Categorical', 'Chronological', 'Generational', 'v', 't']\n"
     ]
    }
   ],
   "source": [
    "print([link.text for link in links[0:10]]) # Выводим ссылки с 1 по 9 включительно"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
