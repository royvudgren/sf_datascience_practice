{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Итоги**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте ещё раз повторим весь путь решения любой задачи оптимизации:\n",
    "\n",
    "1. **Формулирование задачи как задачи оптимизации**. На данном шаге вам необходимо понять, к какому типу относится ваша задача, определить целевую функцию и функции ограничений (если они есть).\n",
    "2. **Определение метода, который будет использоваться**. Здесь вам надо выбрать наиболее подходящий метод оптимизации, понимая особенности вашей задачи и ограничения известных вам методов.\n",
    "3. **Определение начальной точки**. Скорее всего, вы уже запомнили, что реализация каждого алгоритма начиналась с некоторой точки отсчёта, от которой зависит результат. Часто алгоритмы «запускают» сразу из нескольких точек (как, например, в случае градиентного спуска).\n",
    "4. **Переход в следующую точку**. Здесь вы вычисляете следующую точку, используя правило алгоритма, который вы выбрали.\n",
    "5. **Повторение предыдущего шага до сходимости алгоритма**, то есть до того момента, пока не достигнете нуля или нужной точности.\n",
    "\n",
    "Скорее всего, при решении задач вы заметили, что самое главное — это сформулировать вашу практическую задачу в необходимых терминах, перевести её на язык математической модели, а затем подобрать нужный алгоритм. Сами методы уже реализованы в готовых библиотеках Python, и если вы понимаете их суть и ограничения, то для своих задач без проблем можете пользоваться уже готовыми решениями.\n",
    "\n",
    "**ДОПОЛНИТЕЛЬНО**\n",
    "\n",
    "Если вам интересно углубиться в тему оптимизации, в качестве дополнительных материалов можем рекомендовать следующее:\n",
    "\n",
    "* поработать с [**визуализацией к задаче коммивояжёра**](https://www.michalfudala.com/projects/simanneal/);\n",
    "* ознакомиться с [**реализацией метода имитации отжига в Python**](https://habr.com/ru/post/112189/);\n",
    "* обратиться к бесплатному курсу [**\"Combinatorial Optimization\"**](https://ocw.mit.edu/courses/mathematics/18-433-combinatorial-optimization-fall-2003/);\n",
    "* подробнее ознакомиться с процессом оптимизации в [**официальной документации к PuLP**](https://pythonhosted.org/PuLP/index.html);\n",
    "* изучить [**обзор разных методов на основе градиентного спуска**](http://ruder.io/optimizing-gradient-descent/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68eacbc5a3a550d9b1f68bf11bf31e2b39ed4b9985227d4d8c7ee1d286013f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
