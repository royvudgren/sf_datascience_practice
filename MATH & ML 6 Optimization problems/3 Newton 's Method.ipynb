{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Метод Ньютона**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем юните мы познакомились с различными вариациями градиентного спуска. Но для того чтобы наш арсенал методов был более полным и позволял решать самые разные задачи, нам необходимо разобраться и с рядом других алгоритмов. В этом юните мы будем изучать **метод Ньютона**.\n",
    "\n",
    "Метод Ньютона используется во многих алгоритмах машинного обучения. Часто в литературе его сравнивают с градиентным спуском, так как два этих алгоритма очень популярны. Вы уже сталкивались с методом Ньютона, но не знали об этом.\n",
    "\n",
    "В документации для функции **LogisticRegression** из библиотеки scikit-learn представлено пять вариантов алгоритмов оптимизации, которые можно использовать при обучении модели:\n",
    "\n",
    "* 'newton-cg';\n",
    "* 'lbfgs';\n",
    "* 'liblinear';\n",
    "* 'sag';\n",
    "* 'saga'.\n",
    "\n",
    "Последние два являются вариациями стохастического градиентного спуска (а значит вам уже понятен принцип их работы), а с первыми тремя нам только предстоит познакомиться. В этом юните мы рассмотрим алгоритм **'newton-cg'**, в следующем — **'lbfgs'**, а в седьмом юните — **'liblinear'**. Вы будете понимать суть всех методов, представленных в самой популярной библиотеке для машинного обучения, и выбирать подходящий, исходя из особенностей поставленной задачи.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с метода Ньютона. Этот алгоритм работает быстрее, чем градиентный спуск, и тратит меньше времени для достижения минимума, однако у него есть и определённые недостатки, о которых мы поговорим позже.\n",
    "\n",
    "* Метод Ньютона изначально появился как метод решения уравнений вида f(x) = 0.\n",
    "\n",
    "Проиллюстрируем принцип его работы геометрически. Пусть у нас есть график некоторой функции. Проведём к нему касательную в точке xn.\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5a3c5135a9e4da28d101707c4ed16b91/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md6_3_1.png)\n",
    "\n",
    "![](data/7.PNG)\n",
    "\n",
    "Можно посмотреть на это и в анимации:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/b2f35525a4938a45e4d72610779be3c5/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md6_3_2.gif)\n",
    "\n",
    "![](data/8.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример № 1, 2**\n",
    "\n",
    "Найти корень уравнения x**2 - 4*x - 7 = 0, который находится рядом с точкой x = 5, с точностью до тысячных.\n",
    "\n",
    "![](data/9.PNG)\n",
    "\n",
    "**Пример № 2**\n",
    "\n",
    "Найти корни сложного полинома 6*x**5 - 5*x**4 - 4*x**3 + 3*x**2\n",
    "\n",
    "Как мы знаем, к сожалению, для полинома пятой степени нет формулы поиска корней, поэтому будем использовать численные методы. В этих случаях приходится прибегать к числовому линейному приближению.\n",
    "\n",
    "Ниже представлен график нашего полинома. У него три корня: в точках 0, 1 и где-то между ними. Как найти третий корень?\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/7ff22f2332a716cf7b565feba5fa248b/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md6_3_3.png)\n",
    "\n",
    "В методе Ньютона мы берём случайную точку x0, а затем проводим касательную в ней. Точка x1, где эта касательная пересекает ось абсцисс, станет нашим следующим предположением. Так что теперь мы  строим уже касательную в этой точке, и так далее . Мы продолжаем до тех пор, пока не достигнем необходимой точности. В целом, мы можем сделать приближение настолько близким к нулю, насколько хотим.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РЕШЕНИЕ НА ПИТОНЕ\n",
    "\n",
    "Найдите третий корень полинома 6*x**5 - 5*x**4 - 4*x**3 + 3*x**2, взяв за точку старта 0.7. Введите получившееся значение с точностью до трёх знаков после точки-разделителя.\n",
    "\n",
    "Попробуйте реализовать алгоритм с использованием Python на основе алгоритма градиентного спуска, изученного в предыдущем модуле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6296335078534031\n",
      "0.6286680781673306\n",
      "0.6286669787778999\n",
      "0.6286669787764609\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def func1(x):\n",
    "    return 6*x**5-5*x**4-4*x**3+3*x**2\n",
    " \n",
    "def func2(x):\n",
    "    return 30*x**4-20*x**3-12*x**2+6*x\n",
    "init_value = 0.7\n",
    "iter_count = 0\n",
    "x_curr = init_value\n",
    "epsilon = 0.000001\n",
    "f = func1(x_curr)\n",
    " \n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)\n",
    "print(iter_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, мы научились искать приближённые значения для корней уравнения. Но как же это поможет нам найти минимум или максимум для функции?\n",
    "\n",
    "Дело в том, что в задаче оптимизации можно решать не f(x) = 0, а f'(x) = 0 — тогда мы найдём потенциальные точки экстремума.\n",
    "\n",
    "В многомерном случае по аналогичным рассуждениям производная превращается в градиент, а вторая производная превращается в гессиан (матрица вторых производных или, как мы её называли в предыдущем модуле, матрица Гессе). Поэтому в формуле появится обратная матрица.\n",
    "\n",
    "Для многомерного случая формула выглядит следующим образом:\n",
    "\n",
    "![](data/10.PNG)\n",
    "\n",
    "Можно заметить, что эта формула совпадает с формулой для градиентного спуска, но вместо умножения на learning rate (темп обучения) используется умножение на обратную матрицу к гессиану. Благодаря этому функция может сходиться за меньшее количество итераций, так как мы учитываем информацию о выпуклости функции через гессиан. Можно увидеть это на иллюстрации работы двух методов, где метод Ньютона явно сходится быстрее:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/5a6350807f0c71c3c77f61d3372cf322/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/MATHML_md6_3_4.png)\n",
    "\n",
    "Метод Ньютона, если считать в количестве итераций, в многомерном случае (с гессианом) работает быстрее градиентного спуска.\n",
    "\n",
    "Выше мы уже разобрали применение метода Ньютона для поиска корней уравнения. Теперь давайте снова используем его, но уже для оптимизации функции ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **ПРИМЕР ПОИСКА МИНИМУМА ФУНКЦИИ С ПОМОЩЬЮ НЬЮТОНА**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизировать функцию x**3 - 3*x**2 - 45*x + 40.\n",
    "\n",
    "Находим производную функции:\n",
    "\n",
    "f' = 3*x**2 - 6*x - 45\n",
    "\n",
    "Находим вторую производную:\n",
    "\n",
    "f'' = 6*x - 6\n",
    "\n",
    "Сразу определим их в Python, чтобы можно было параллельно решить задачу и с помощью программирования:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func1(x):\n",
    "    return 3*x**2 - 6*x -45\n",
    "def func2(x):\n",
    "    return 6*x - 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо взять какую-нибудь изначальную точку. Например, пусть это будет точка x = 42. Также нам необходима точность — её возьмем равной 0.0001. На каждом шаге будем переходить в следующую точку по уже упомянутой выше формуле:\n",
    "\n",
    "![](data/11.PNG)\n",
    "\n",
    "Но, к счастью, нам совсем не обязательно высчитывать всё вручную — воспользуемся Python и распишем наш алгоритм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.695121951219512\n",
      "11.734125501243229\n",
      "7.1123493600499685\n",
      "5.365000391507974\n",
      "5.015260627016227\n",
      "5.000029000201801\n",
      "5.000000000105126\n",
      "5.000000000000001\n"
     ]
    }
   ],
   "source": [
    "init_value = 42\n",
    "iter_count = 0\n",
    "x_curr = init_value\n",
    "epsilon = 0.0001\n",
    "f = func1(x_curr)\n",
    "\n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m x_curr\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimize\u001b[39;00m \u001b[39mimport\u001b[39;00m newton\n\u001b[1;32m---> 15\u001b[0m newton(func\u001b[39m=\u001b[39mf_0,x0\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m,fprime\u001b[39m=\u001b[39mf_1, tol\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f_0' is not defined"
     ]
    }
   ],
   "source": [
    "# Можно объединить всё в одну функцию:\n",
    "\n",
    "def newtons_method(f, der, eps, init):\n",
    "    iter_count = 0\n",
    "    x_curr = init\n",
    "    f = f(x_curr)\n",
    "    while (abs(f) > eps):\n",
    "        f = f(x_curr)\n",
    "        f_der = der(x_curr)\n",
    "        x_curr = x_curr - (f)/(f_prime)\n",
    "        iter_count += 1\n",
    "    return x_curr\n",
    " \n",
    "from scipy.optimize import newton\n",
    "newton(func=f_0,x0=50,fprime=f_1, tol=0.0001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ДОСТОИНСТВА МЕТОДА НЬЮТОНА**\n",
    "\n",
    "* Если мы минимизируем квадратичную функцию, то с помощью метода Ньютона можно попасть в минимум целевой функции за один шаг.\n",
    "\n",
    "* Также этот алгоритм сходится за один шаг, если в качестве минимизируемой функции выступает функция из класса поверхностей вращения (т. е. такая, у которой есть симметрия).\n",
    "\n",
    "* Для несимметричной функции метод не может обеспечить сходимость, однако скорость сходимости всё равно превышает скорость методов, основанных на градиентном спуске."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **НЕДОСТАТКИ МЕТОДА НЬЮТОНА**\n",
    "\n",
    "* Этот метод очень чувствителен к изначальным условиям.\n",
    "\n",
    "  * При использовании градиентного спуска мы всегда гарантированно движемся по антиградиенту в сторону минимума. В методе Ньютона происходит подгонка параболоида к локальной кривизне, и затем алгоритм движется к неподвижной точке данного параболоида. Из-за этого мы можем попасть в максимум или седловую точку. Особенно ярко это видно на невыпуклых функциях с большим количеством переменных, так как у таких функций седловые точки встречаются намного чаще экстремумов.\n",
    "\n",
    "  * Поэтому здесь необходимо обозначить ограничение: метод Ньютона стоит применять только для задач, в которых целевая функция выпуклая.\n",
    "\n",
    "  * Впрочем, это не является проблемой. В линейной регрессии или при решении задачи классификации с помощью метода опорных векторов или логистической регрессии мы как раз ищем минимум у выпуклой целевой функции, то есть данный алгоритм подходит нам во многих случаях.\n",
    "\n",
    "* Также метод Ньютона может быть затратным с точки зрения вычислительной сложности, так как требует вычисления не только градиента, но и гессиана и обратного гессиана (при делении на матрицу необходимо искать обратную матрицу).\n",
    "\n",
    "  * Если у задачи много параметров, то расходы на память и время вычислений становятся астрономическими. Например, при наличии 50 параметров нужно вычислять более 1000 значений на каждом шаге, а затем предстоит ещё более 500 операций нахождения обратной матрицы. Однако метод всё равно используют, так как выгода от быстрой сходимости перевешивает затраты на вычисления."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на его ограниченное практическое применение, метод Ньютона по-прежнему представляет большую ценность. Он имеет большое преимущество перед градиентным спуском в силу своей быстроты и отсутствия необходимости в настройке гиперпараметра шага (мы помним, что в градиентном спуске выбор шага — довольно непростая задача, а здесь можно обойтись без этого). Причём преимущество в быстроте очень ощутимое: в сравнении на реальных данных метод Ньютона находит решение задачи за 3 итерации, а градиентный спуск — за 489. То есть мы сильно выигрываем в скорости сходимости, а для анализа данных это очень важно, ведь экономия времени и вычислительных ресурсов позволяет решать задачи быстрее.\n",
    "\n",
    "?\n",
    "Мы увидели, какой эффективной может быть оптимизация второго порядка при правильном использовании. Но что, если бы мы могли каким-то образом использовать эффективность, полученную при использовании производных второго порядка, но при этом избежать вычислительных затрат на вычисление обратного гессиана? Другими словами — можем ли мы создать алгоритм, который будет своего рода гибридом между градиентным спуском и методом Ньютона, где мы сможем получать более быструю сходимость, чем градиентный спуск, но меньшие вычислительные затраты на каждую итерацию, чем в методе Ньютона?\n",
    "\n",
    "Оказывается, такой алгоритм существует. Точнее, целый класс таких методов оптимизации, называемых **квазиньютоновскими методами**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ЗАДАЧИ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.21111111111111\n",
      "9.756461564762278\n",
      "9.727252176332618\n",
      "9.72713442131889\n",
      "9.727134419408875\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Дана функция x**3 - 72*x - 220.\n",
    "# Найдите решение уравнения f(x) = 0 для поиска корня в окрестностях точки x0 = 12.\n",
    "# Ответ округлите до трёх знаков после точки-разделителя.\n",
    "\n",
    "def func1(x):\n",
    "    return x**3 - 72*x - 220\n",
    " \n",
    "def func2(x):\n",
    "    return 3*(x**2) - 72\n",
    "\n",
    "init_value = 12\n",
    "iter_count = 0\n",
    "x_curr = init_value\n",
    "epsilon = 0.0001\n",
    "f = func1(x_curr)\n",
    " \n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)\n",
    "print(iter_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите положительный корень для уравнения x**2 + 9 *x - 5 = 0.\n",
    "\n",
    "В качестве стартовой точки возьмите x0 = 2.2.\n",
    "\n",
    "Расчёт произведите поэтапно или с помощью Python.\n",
    "\n",
    "Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7343283582089555\n",
      "0.5291259698087832\n",
      "0.5249395544696249\n",
      "0.5249378105607477\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "def func1(x):\n",
    "    return x**2 + 9 *x - 5\n",
    " \n",
    "def func2(x):\n",
    "    return 2*x + 9\n",
    "\n",
    "init_value = 2.2\n",
    "iter_count = 0\n",
    "x_curr = init_value\n",
    "epsilon = 0.001\n",
    "f = func1(x_curr)\n",
    " \n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)\n",
    "print(iter_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода Ньютона найдите точку минимума для функции 8*(x**3) - 2*(x**2) - 450.\n",
    "\n",
    "Для расчётов используйте Python.\n",
    "\n",
    "В качестве стартовой точки возьмите 42, точность примите за 0.0001.\n",
    "\n",
    "Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.041749502982107\n",
      "10.562707090133793\n",
      "5.323351550447383\n",
      "2.7040050774153417\n",
      "1.3949941413301903\n",
      "0.7418109325525483\n",
      "0.41784523900811205\n",
      "0.26096925221473555\n",
      "0.19169814030401197\n",
      "0.16955770984744145\n",
      "0.1667151339969682\n",
      "0.1666666807529666\n",
      "0.16666666666666785\n"
     ]
    }
   ],
   "source": [
    "def func1(x):\n",
    "    return 24*(x**2) - 4*x\n",
    "def func2(x):\n",
    "    return 48*x - 4\n",
    "\n",
    "\n",
    "init_value = 42\n",
    "iter_count = 0\n",
    "x_curr = init_value\n",
    "epsilon = 0.0001\n",
    "f = func1(x_curr)\n",
    "\n",
    "while (abs(f) > epsilon):\n",
    "    f = func1(x_curr)\n",
    "    f_prime = func2(x_curr)\n",
    "    x_curr = x_curr - (f)/(f_prime)\n",
    "    iter_count += 1\n",
    "    print(x_curr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68eacbc5a3a550d9b1f68bf11bf31e2b39ed4b9985227d4d8c7ee1d286013f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
