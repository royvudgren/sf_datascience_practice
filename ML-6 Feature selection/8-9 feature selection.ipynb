{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Отбор признаков: мотивация**"]},{"cell_type":"markdown","metadata":{},"source":["[**Отбор признаков**](https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/jump_to_id/68496461c02343d0a7b1fd901edd40bc) — это процесс выбора важных признаков, оказывающих наибольшее влияние на предсказание."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"t_IvORKWGuCH"},"outputs":[],"source":["import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error"]},{"cell_type":"markdown","metadata":{"id":"FtTudvkQGzRk"},"source":["### **Загрузка данных**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"CiadW5D9G07U"},"outputs":[],"source":["%%capture\n","!wget https://www.dropbox.com/s/64ol9q9ssggz6f1/data_ford_price.xlsx"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gmll87tAG2rK"},"outputs":[],"source":["data = pd.read_excel('data/data_ford_price.xlsx') "]},{"cell_type":"markdown","metadata":{"id":"dt3vhRQ2G_uP"},"source":["### **Предобработка данных**"]},{"cell_type":"markdown","metadata":{},"source":["Давайте оценим влияние мультиколлинеарности на линейную регрессию:"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"CJdK-t3MHDSp"},"outputs":[],"source":["data = data[['price','year', 'cylinders', 'odometer', 'lat', 'long', 'weather']]\n","data.dropna(inplace = True)\n","\n","y = data['price']\n","x = data.drop(columns='price')\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"markdown","metadata":{"id":"kqjEj0ABG4ZD"},"source":["### **Обучение модели**"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650361775695,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"K0aIWfwpHSHN","outputId":"9d5779ab-7fea-43e4-f7d6-62317dfcc079"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 4682.957\n"]}],"source":["model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{"id":"TznnlORnHisT"},"source":["### **Удаление избыточного признака**"]},{"cell_type":"markdown","metadata":{},"source":["Мы выяснили, что у нас присутствует сильная зависимость между lat и weather. Удалим lat, так как этот признак, в отличие от weather, необходимо округлять."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"2uKP_vEMHoBa"},"outputs":[],"source":["x.drop('lat', axis = 1, inplace = True)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"A7f7kV-6HrrL"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1650361779668,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"pJQpOM9kHtSe","outputId":"709029e0-e13b-4f2b-92f7-9fa807a81b0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["MAE: 4672.930\n"]}],"source":["model = LinearRegression()\n","model.fit(X_train, y_train)\n","y_predicted = model.predict(X_test)\n"," \n","mae = mean_absolute_error(y_test, y_predicted)\n","print('MAE: %.3f' % mae)"]},{"cell_type":"markdown","metadata":{},"source":["✍ Итак, мы вспомнили о понятии мультиколлинеарности и о его влиянии на отбор признаков. В следующем юните мы разберём автоматические методы отбора признаков, влияющих на качество моделирования."]},{"cell_type":"markdown","metadata":{"id":"E54vkz2xIGWm"},"source":["#  **Отбор признаков: классификация методов**"]},{"cell_type":"markdown","metadata":{},"source":["Методы отбора признаков предназначены для уменьшения количества входных переменных до тех значений, которые наиболее полезны для предсказательной способности модели.\n","\n","Фича - признак\n","![](https://lms.skillfactory.ru/assets/courseware/v1/a9a03b27389e7e8d9b8180f545260056/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml6-9_5.png)"]},{"cell_type":"markdown","metadata":{"id":"dUnTavGgIpj0"},"source":["### **МЕТОД РЕКУРСИВНОГО ИСКЛЮЧЕНИЯ ПРИЗНАКОВ (RFE)**"]},{"cell_type":"markdown","metadata":{},"source":["**Метод рекурсивного исключения признаков (RFE)** предполагает выбор признаков путём рекурсивного рассмотрения всё меньших и меньших наборов фичей.\n","\n","Сначала RFE обучается на изначальной выборке, и происходит оценка важности каждого признака. Затем наименее важные фичи удаляются. Эта процедура рекурсивно повторяется на сокращённом наборе до тех пор, пока в конечном итоге не будет достигнуто желаемое количество признаков в выборке."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"UYdiW0RWIZ5V"},"outputs":[],"source":["from sklearn.feature_selection import RFE"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"n3MW_xlPIJHd"},"outputs":[],"source":["y = data['price']\n","x = data.drop(columns='price')\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=40)"]},{"cell_type":"markdown","metadata":{},"source":["Выделим три наиболее значимых признака:"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1650361787999,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"qxZGlxQYITTm","outputId":"cf3cfc7c-1bb2-4a2b-b8c4-26a5857e251a"},"outputs":[{"data":{"text/plain":["array(['year', 'cylinders', 'lat'], dtype=object)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["estimator = LinearRegression()\n","selector = RFE(estimator, n_features_to_select=3, step=1)\n","selector = selector.fit(X_train, y_train)\n"," \n","selector.get_feature_names_out()"]},{"cell_type":"markdown","metadata":{},"source":["Также узнаем, как RFE проранжировал все доступные признаки:"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1650361789809,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"VdZbOvqdIebk","outputId":"ac89f779-2388-4185-8647-b8addd1cbfac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['year', 'cylinders', 'odometer', 'lat', 'long', 'weather'], dtype='object')\n","[1 1 4 1 3 2]\n"]}],"source":["# 3 самых важных признака\n","print(X_train.columns)\n","# сила влияния признаков\n","print(selector.ranking_)"]},{"cell_type":"markdown","metadata":{"id":"_KhZgXCkK3Ap"},"source":["##  **МЕТОДЫ ВЫБОРА ПРИЗНАКОВ НА ОСНОВЕ ФИЛЬТРОВ**"]},{"cell_type":"markdown","metadata":{},"source":["В качестве фильтров для выбора признаков используются уже знакомые нам статистики, такие как коэффициент **корреляции Пирсона**, **ANOVA** и т. д. При этом выбор статистических показателей сильно зависит от типов переменных в данных.\n","\n","Чем больше известно о типе данных, тем проще выбрать подходящую статистическую меру для метода отбора признаков на основе фильтра. Ниже приведена схема-помощник в выборе метода селекции признаков.\n","\n","Если входящий признак числовой, то если и на выходе тоже число - это задача регрессии, если же на выходе категориальный признак - то это задача классификации.\n","\n","![](https://lms.skillfactory.ru/assets/courseware/v1/8f55a77ec813c98e6e48f2efff923f23/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml6-9_3.png)"]},{"cell_type":"markdown","metadata":{},"source":["Библиотека **sklearn** обеспечивает реализацию большинства полезных статистических показателей, например:\n","\n","* коэффициента корреляции Пирсона: [**f_regression()**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html);\n","* дисперсионного анализа ANOVA: [**f_classif()**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html);\n","* хи-квадрата: [**chi2()**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html);\n","* взаимной информации: [**mutual_info_classif()**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html) и [**mutual_info_regression()**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_regression.html).\n","\n","Кроме того, библиотека **SciPy** обеспечивает реализацию многих других статистических данных, таких как тау Кендалла ([**kendalltau**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html)) и ранговая корреляция Спирмена ([**spearmanr**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html)).\n","***\n","**sklearn** также предоставляет множество различных методов фильтрации после расчёта статистики для каждой входной переменной с целевой.\n","\n","Два наиболее популярных метода:\n","\n","* выбор k лучших переменных: [**SelectKBest**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html);\n","* выбор переменных верхнего процентиля: [**SelectPercentile**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectPercentile.html)."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"mVHuMD0eK8or"},"outputs":[],"source":["from sklearn.feature_selection import SelectKBest, f_regression"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":413,"status":"ok","timestamp":1650361806172,"user":{"displayName":"Ketrin Trofimova","userId":"05400058012601189465"},"user_tz":-180},"id":"dc2EPKG5K39w","outputId":"4bc13ef2-9c06-47c6-f892-566135ee3dcd"},"outputs":[{"data":{"text/plain":["array(['year', 'cylinders', 'odometer'], dtype=object)"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["selector = SelectKBest(f_regression, k=3)\n","selector.fit(X_train, y_train)\n"," \n","selector.get_feature_names_out()"]},{"cell_type":"markdown","metadata":{},"source":["На этот раз odometer оказался в топе."]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Отбор_признаков.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"vscode":{"interpreter":{"hash":"c68eacbc5a3a550d9b1f68bf11bf31e2b39ed4b9985227d4d8c7ee1d286013f5"}}},"nbformat":4,"nbformat_minor":0}
