{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ансамблирование: блендинг и стекинг**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Стекинг (stacking)** — алгоритм построения ансамбля, в котором параллельно и независимо друг от друга обучаются несколько базовых моделей (необязательно одной природы), а их предсказания используются для обучения **метамодели** (финальная модель) как факторы.\n",
    "\n",
    "Предсказания базовых алгоритмов называются **метапризнаками**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **БЛЕНДИНГ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простейшая реализация стекинга заключается в **блендинге** (blending). \n",
    "\n",
    "Схематично блендинг можно представить следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/e6928c858c286dde36c590f57d4d6b66/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst-3-ml-8-5.png)\n",
    "\n",
    "Суть блендинга состоит в следующем: предположим у нас есть обучающая выборка ***X***, которую мы делим пополам. Первая часть используется для обучения базовых моделей, а на второй базовые модели делают предсказания – метапризнаки, на которых уже и обучается в дальнейшем метамодель. \n",
    "\n",
    "Недостатки блендинга видны невооруженным глазом: ни базовые модели, ни метамодель не обучаются на полных данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **СТЕКИНГ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для решения этой проблемы используется усовершенствованная модель блендинга, которая имеет полноценное название — **стекинг**. Идея борьбы с недостатком блендинга — использование **кросс-валидации**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим как обучается классический стекинг. Пусть у нас есть таблица с примерами ***X*** и ответами на них ***y***. Количество признаков — ***m***, количество наблюдений — ***n***, количество моделей в стекинге — ***K***.\n",
    "\n",
    "<center>1</center>\n",
    "\n",
    "Обучающая выборка разбивается на ***L*** равных частей, называемых **фолдами**. Например, для трёх фолдов (***L = 3***) схематично это будет выглядеть следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/a8d9de09d8f6a07ac8b04d84fa837454/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml3-8_1.png)\n",
    "\n",
    "<center>2</center>\n",
    "\n",
    "Затем для каждой базовой модели эти фолды перебираются следующим образом: на каждом шаге фиксируются ***L - 1*** фолдов для обучения базовых моделей и один фолд для предсказания (в случае бинарной классификации каждая модель предсказывает вероятность принадлежности к классу 1, в случае мультиклассовой классификации — к каждому классу). В результате будет сформировано ***L*** предсказаний, из которых формируется метапризнак ***Mj***, где ***j*** — номер модели:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/c3a923e9a53df27fe9098d747eda6f1f/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml3-8_2.png)\n",
    "\n",
    "Такой подход к формированию метапризнаков позволяет избежать переобучения. Действительно, можно рассматривать ***L - 1***-фолд как обучающую выборку, а оставшийся — как тестовую. Таким образом, мы обучаемся на тренировочной выборке, но предсказания делаем для той выборки, которую ещё не видели.\n",
    "\n",
    "<center>3</center>\n",
    "\n",
    "После того как мы проделаем шаг 2 для всех базовых моделей, мы получим новый набор данных, состоящий из ***K*** метапризнаков — предсказаний каждой из моделей. Предсказания моделей будут использоваться в качестве метапризнаков, на которых будет обучена метамодель.\n",
    "\n",
    "Пусть мы взяли три разных модели, т. е. ***K = 3***. Это будет выглядеть следующим образом:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/b7b2bde8db3159532ee0042b395858a6/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml3-8_3.png)\n",
    "\n",
    "*Примечание. Кроме метафакторов, метамодель может использовать для своего обучения изначальные признаки из исходного набора данных.*\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как работает алгоритм на конкретной таблице. Пусть у нас есть некоторый набор данных из **четырёх** признаков, характеризующих клиента (x_0, x_1, x_2 и x_3), и **восемь** наблюдений. На основе этих признаков необходимо предсказать **бинарный целевой признак** (y) покупки товара со значениями 1 (купил) и 0 (не купил). Будем использовать стекинг, состоящий из трёх различных моделей.\n",
    "\n",
    "Разбиваем выборку на четыре фолда, то есть в каждом фолде будет по **две** строки таблицы (обозначены цветом). Обучаем каждую модель на **трёх** из этих фолдов и делаем предсказание вероятности покупки для оставшегося.\n",
    "\n",
    "Из предсказаний будет сформировано **три метапризнака** (по одному на каждую базовую модель). Это будут предсказанные базовыми классификаторами вероятности покупки (вероятность принадлежности к классу 1).\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/de1cba156b331d27e229eec3ec107819/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml3-8_4.png)\n",
    "\n",
    "Формируем новый набор данных и отправляем его в метамодель, которая уже и делает финальное предсказание целевого признака покупки:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/476d2d3365cad4c4b9cf2738ef982ca4/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml3-8_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае, когда у нас есть ***K*** моделей, общая схема стекинга будет иметь вид:\n",
    "\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/bbe06be5289a83d9300f7d073f4ad468/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/dst3-ml3-8_6.png)\n",
    "\n",
    "*Важно понимать, стекинг — это чистая эвристика, эффективность которой доказана только практическим применением. Стекинг использует тот же подход, что и нейронные сети: предсказания предыдущего этапа (слоя) используются в качестве признаков для следующего этапа (слоя).*\n",
    "\n",
    "*С точки зрения смещения и разброса, стекинг не имеет прямой математической интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, но гарантий уменьшения смещения или разброса нет.*\n",
    "***\n",
    "Есть некоторые рекомендации, как правильно строить стекинг:\n",
    "\n",
    "* В качестве метамоделей лучше всего применять простые модели: например, для задачи регрессии — линейную регрессию, а для задачи классификации — логистическую регрессию.\n",
    "* В качестве базовых моделей лучшего всего использовать модели различной природы.\n",
    "\n",
    "Из всех ансамблевых методов стекинг применяется реже всего. Главная причина: так как используется много разных моделей, необходимо подбирать их внешние параметры (коэффициенты регуляризации, глубина деревьев, число деревьев, темп обучения и т. д.) в совокупности, а подбор огромного количества параметров очень затратен по времени (мы убедились в этом в модуле по подбору внешних параметров моделей).\n",
    "\n",
    "Вторая причина — в отличие от бэггинга и бустинга, для стекинга нет каких-то готовых решений, таких как случайный лес и градиентный бустинг над деревьями. Базовые модели нужно подбирать самому, а какие из них подойдут лучше всего — открытый вопрос.\n",
    "\n",
    "Но, несмотря на эти недостатки, при грамотном подходе опытные специалисты выигрывают соревнования на Kaggle благодаря стекингу. Хотя зачастую таких участников называют «читерами» (от англ. cheat — «жульничать, обманывать»), ведь часто они собирают чуть ли не все возможные ML-модели в стекинг, запускают на мощном сервере подбор внешних параметров и комбинации из этих моделей в стекинге получают заветные 1.5 % прироста качества модели. На Kaggle даже существует фраза — «настекали».\n",
    "\n",
    "В реальных условиях такой прирост значит мало, поэтому мы не будем концентрироваться на стекинге в нашем курсе, но пример разберём."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **СТЕКИНГ В SKLEARN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стекинг для задачи регрессии имеет реализацию в библиотеке scikit-learn в классе **StackingRegressor**, для задачи классификации — в классе **StackingClassifier**. На вход подаётся список базовых моделей (атрибут **estimators**) и метамодель (атрибут **final_estimator**).\n",
    "\n",
    "***Примечание. Стоит понимать, что для задачи регрессии все базовые модели должны быть регрессорами, а для задачи классификации — классификаторами.*** \n",
    "\n",
    "Попробуем на практике применить стекинг, используя реализацию из библиотеки sklearn. В качестве входных данных будем использовать данные про диабет, использованные ранее. Обратимся снова к коду и обучим модель на данных.\n",
    "\n",
    "Как и все ансамбли, модель стекинга находится в модуле **ensemble**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes(as_frame=True)\n",
    "X = data['frame']\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Основные параметры StackingRegressor:**\n",
    "\n",
    "* **estimators** — список из кортежей базовых моделей в виде (str, model). Первым элементом в каждом кортеже идет строка с именем модели, вторым — собственно сама модель.\n",
    "* **final_estimator** — метамодель.\n",
    "* **cv** — количество фолдов, на которые делится выборка. По умолчанию используется пять фолдов.\n",
    "\n",
    "Будем строить стекинг на следующих моделях:\n",
    "\n",
    "* 'dt' — дерево решений;\n",
    "* 'lr' — ридж-регрессия, линейная модель регрессии с L2-регуляризацией;\n",
    "* случайный лес с количеством деревьев, равным 10, в качестве метамодели.\n",
    "\n",
    "Примечание. В данном случае мы рассматриваем **RidgeCV**, которая представляет собой ридж-регрессию со встроенной кросс-валидацией по методу **Leave-One-Out Cross-Validation**. Подробнее читайте по [ссылке](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html).\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим список кортежей в формате (\"наименование модели\", модель) из этих моделей, и назовем его estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создаем список кортежей вида: (наименование модели, модель)\n",
    "estimators = [\n",
    "    ('lr', RidgeCV()),\n",
    "    ('dt',  DecisionTreeRegressor(random_state=42))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда список из базовых моделей готов, создадим объект класса **StackingRegressor**. Первым аргументом передаём список из базовых моделей. Будем использовать в качестве метамодели модель случайного леса. Для этого передаём её в параметр **final_estimator**. Остальные параметры оставим по умолчанию.\n",
    "\n",
    "Обучаем модель с помощью метода **fit()**, делаем предсказание классов с помощью метода **predict()**, а затем считаем метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для стекинга 0.81\n"
     ]
    }
   ],
   "source": [
    "#Создаем объект класса стекинг\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                          random_state=42)\n",
    ")\n",
    " \n",
    "#Обучаем модель\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_stack = reg.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для стекинга {round(mean_squared_error(y_test, y_pred_stack),2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть на метапризнаки можно с помощью метода **transform()**. Для этого в метод нужно передать матрицу наблюдений X. В результате вызова метода для всех объектов каждая из трёх моделей сделает предсказание вероятностей и вернёт матрицу из двух столбцов. Оформим её в виде DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meta_feature1</th>\n",
       "      <th>meta_feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.000001</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.000002</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.000007</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122.000005</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   meta_feature1  meta_feature2\n",
       "0     154.000000          154.0\n",
       "1     192.000001          192.0\n",
       "2     116.000002          116.0\n",
       "3      81.000007           81.0\n",
       "4     122.000005          122.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data = reg.transform(X_train)\n",
    "#Создаем DataFrame\n",
    "meta_df = pd.DataFrame(\n",
    "    meta_data, #содержимое таблицы\n",
    "    columns=['meta_feature1', 'meta_feature2',] #название столбцов\n",
    ")\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **ЗАДАЧА**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения задания используйте набор данных о диабете, который представлен в ноутбуке с примерами.\n",
    "\n",
    "Постройте стекинг из следующих базовых моделей:\n",
    "\n",
    "* Ридж-регрессия (RidgeCV());\n",
    "* Линейная регрессия.\n",
    "\n",
    "В качестве метамодели используйте случайный лес с количеством деревьев 100, максимальной глубиной 10, все параметры для базовых моделей стандартные. Для всех алгоритмов параметр random_state=42.\n",
    "\n",
    "Сделайте предсказание целевой метки для тестового набора данных. Рассчитайте метрику MSE для набора данных и запишите её в качестве ответа с точностью до одного знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество предсказания по MSE для стекинга 0.3\n"
     ]
    }
   ],
   "source": [
    "#Создаем список кортежей вида: (наименование модели, модель)\n",
    "estimators = [\n",
    "    ('rcv', RidgeCV()),\n",
    "    ('lrg',  linear_model.LinearRegression())\n",
    "]\n",
    "\n",
    "#Создаем объект класса стекинг\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=100,\n",
    "                                          max_depth=10,\n",
    "                                          random_state=42)\n",
    ")\n",
    " \n",
    "#Обучаем модель\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_stack = reg.predict(X_test)\n",
    "print(f'Качество предсказания по MSE для стекинга {round(mean_squared_error(y_test, y_pred_stack),1)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68eacbc5a3a550d9b1f68bf11bf31e2b39ed4b9985227d4d8c7ee1d286013f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
